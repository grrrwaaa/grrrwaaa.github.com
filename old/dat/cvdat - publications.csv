Title,In P,Date,Type,Authors,Trainee,Publication,Series,Vol,Num,pp,Editors,Venue,Publisher,DOI,ISBN,URL,URL2,Abstract,Accolades,Commentary,year,month,monthname,bibtex_entrytype,bibtex_id
Third-Order Ambisonic Extensions for Max/MSP with Musical Applications.,,2006/8,Conference,"Wakefield, Graham; ",,Proceedings of the International Computer Music Conference,,,,123-126,"Georg Essl, Ichiro Fujinaga","New Orleans, USA",International Computer Music Association,,0-9713192-4-3,http://quod.lib.umich.edu/i/icmc/bbp2372.2006.027/-third-order-ambisonic-extensions-for-maxmsp-with-musical?view=image,http://hdl.handle.net/2027/spo.bbp2372.2006.027,This paper describes a package of extensions (externals) for Cycling `74's Max/MSP software to facilitate the exploration of Ambisonic techniques of up to third order. Areas of exploration well suited to the Max/MSP environment and techniques for composition within the Ambisonic domain using the presented externals are described.,,,2006,8,August,inproceedings,wakefield_2006_thirdorderambisonicextensionsformaxmspwithmusicalapplications
"A platform for computer music composition, Interleaving Sample-Accurate Synthesis and Control",,2007/7,MS Thesis,"Wakefield, Graham David; ",,,,,,,"Roads, Curtis; Kuchera-Morin, JoAnn; Novak, Marcos; Pope, Stephen","Santa Barbara, USA",University of California Santa Barbara,,,http://www.mat.ucsb.edu/~wakefield/pubs/07_Wakefield_MSThesis_Vessel.pdf,,"The rich new terrains offered by computer music invite the exploration of new techniques to compose within them. The computational nature of the medium has suggested algorithmic approaches to composition in the form of generative musical structure at the note level and above, and audio signal processing at the level of individual samples. In the region between these levels, the domain of microsound, we may wish to investigate the musical potential of sonic particles that interrelate both signal processing and generative structure. In this thesis I present a software platform (`Vessel') for the exploration of such potential. In particular, a solution to the efficient scheduling of interleaved sound synthesis and algorithmic control with sample accuracy is expounded. The formal foundations, design and implementation are described, the project is contrasted with existing work, and avenues for musical application and future exploration are proposed.",,,2007,7,July,mastersthesis,wakefield_2007_aplatformforcomputermusiccompositioninterleavingsampleaccuratesynthesisandcontrol
Real-time multimedia composition using lua,,2007/7,Conference,"Smith, Wesley; ",,Proceedings of the Digital Art Weeks,,,,,Stefan M&uuml;ller Arisona,"Zurich, Switzerland",Digital Art Weeks International,,,,,"In this paper, we present a new interface for programming multimedia compositions in Max/ MSP/Jitter using the Lua scripting language. Lua is extensible and efficient making it an ideal choice for designing a programmatic interface for multimedia compositions. First, we discuss the distinctions of graphical and textual interfaces for composition and the requirements for a productive compositional workflow, and then we describe domain specific implementations of Lua bindings as Max externals for graphics and audio in that order.",,,2007,7,July,inproceedings,smith_2007_realtimemultimediacompositionusinglua
Experiencing audio and music in a fully immersive environment,,2007/8,Conference,"Amatriain, Xavier; Castellanos, Jorge; Höllerer, Tobias; Kuchera-Morin, JoAnn; Pope, Stephen T; Wakefield, Graham; Wolcott, Will; ",,International Symposium on Computer Music Modeling and Retrieval: Sense of Sounds,Information Systems and Applications,4969,,380-400,"Richard Kronland-Martinet, S&oslashlvi Ystad, Kristoffer Jensen",,"Springer, Berlin, Heidelberg",10.1007/978-3-540-85035-9,978-3-540-85034-2,http://link.springer.com/chapter/10.1007%2F978-3-540-85035-9_27,http://dx.doi.org/10.1007/978-3-540-85035-9,"The UCSB Allosphere is a 3-story-high spherical instrument in which virtual environments and performances can be experienced in full immersion. The space is now being equipped with high-resolution active stereo projectors, a 3D sound system with several hundred speakers, and with tracking and interaction mechanisms. The Allosphere is at the same time multimodal, multimedia, multi-user, immersive, and interactive. This novel and unique instrument will be used for research into scientific visualization/auralization and data exploration, and as a research environment for behavioral and cognitive scientists. It will also serve as a research and performance space for artists exploring new forms of art. In particular, the Allosphere has been carefully designed to allow for immersive music and aural applications. In this paper, we give an overview of the instrument, focusing on the audio subsystem. We give the rationale behind some of the design decisions and explain the different techniques employed in making the Allosphere a truly general-purpose immersive audiovisual lab and stage. Finally, we present first results and our experiences in developing and using the Allosphere in several prototype projects.",,,2007,8,August,inproceedings,amatriain_2007_experiencingaudioandmusicinafullyimmersiveenvironment
Using lua for multimedia composition,,2007/8,Conference,"Wakefield, G; Smith, W; ",,Proceedings of the International Computer Music Conference,,,,341-344,,"Copenhagen, Denmark",International Computer Music Association,,,,,"In this paper, we present new opportunities to overcome some of the inherent limitations of a visual data-flow environment such as Max/MSP/Jitter, by using domain specific (audio and graphical) extensions of the Lua programming language as libraries (externals). Lua is flexible, extensible and efficient, making it an ideal choice for designing a programmatic interface for multimedia composition.",,,2007,8,August,inproceedings,wakefield_2007_usingluaformultimediacomposition
Computational audiovisual composition using lua,,2008/1,Chapter,"Smith, Wesley; Wakefield, Graham; ",,"Transdisciplinary Digital Art. Sound, Vision and the New Screen",Communications in Computer and Information Science,7,,213-228,"Randy Adams, Steve Gibson, Stefan M&uuml;ller Arisona",,Springer Berlin Heidelberg,10.1007/978-3-540-79486-8,978-3-540-79486-8,http://link.springer.com/chapter/10.1007/978-3-540-79486-8_19,http://dx.doi.org/10.1007/978-3-540-79486-8,"We describe extensions to the Lua programming language constituting a novel platform to support practice and investigation in computational audiovisual composition. Significantly, these extensions enable the tight real-time integration of computation, time, sound and space, and follow a modus operandi of development going back to immanent properties of the domain.",,,2008,1,January,incollection,smith_2008_computationalaudiovisualcompositionusinglua
"The AlloBrain: an interactive stereographic, 3D audio immersive environment",,2008/4,Conference,"Wakefield, Graham; Kuchera-Morin, JoAnn; Novak, Marcos; Overholt, Dan; Putnam, Lance; Thompson, John; Smith, Wesley; ",,CHI Conference Workshop on Sonic Interaction Design,,,,,Davide Rocchesso et al.,"Florenz, Italy",ACM,,978-1-60558-012-8/08/04,,,"This document describes the AlloBrain, the debut content created for presentation in the AlloSphere at the University of California, Santa Barbara, and the Cosm toolkit for the prototyping of interactive immersive environments using higher-order Ambisonics and stereoscopic projections. The Cosm toolkit was developed in order to support the prototyping of immersive applications that involve both visual and sonic interaction design. Design considerations and implementation details of both the Cosm toolkit and the AlloBrain are described in detail, as well as the development of custom human-computer interfaces and new audiovisual interaction methodologies within a virtual environment.",,"The article introduces the first project created for the CNSI AlloSphere at UC Santa Barbara (a 3-storey spherical CAVE-like environment), which provides an interactive, navigable world visualizing and sonifying fMRI brain data, of which I was the primary implementor. The article was extended for the International Journal of Human Computer Studies.",2008,4,April,inproceedings,wakefield_2008_theallobrainaninteractivestereographic3daudioimmersiveenvironment
Instructional Tools in Educational Measurement and Statistics (ITEMS) for School Personnel: Evaluation of Three Web‐Based Training Modules,,2008/6,Journal,"Zwick, Rebecca; Sklar, Jeffrey C; Wakefield, Graham; Hamilton, Cris; Norman, Alex; Folsom, Douglas; ",,Educational Measurement: Issues and Practice,,27,2,14-27,,,Wiley Online Library,,,,,,,,2008,6,June,article,zwick_2008_instructionaltoolsineducationalmeasurementandstatisticsitemsforschoolpersonnelevaluationofthreewebbasedtrainingmodules
Artificial Nature as an Infinite Game,,2008/7,Conference,"Ji, Haru; Wakefield, Graham; ",,Proceedings of ASIAGRAPH,,,,,,"Shanghai, China",ASIAGRAPH,,,,,"A virtual embodiment of an auto-creative world: generative, interactive transmodal media art installation bringing forth an ecosystem of creativity through a meshwork of strata (geo-, chemo-, bio-, sono-), re-questioning the meanings and relationships of nature, culture, life and beauty.",,,2008,7,July,inproceedings,ji_2008_artificialnatureasaninfinitegame
Artificial Nature as an Infinite Game,,2008/8,Conference,"Ji, Haru; Wakefield, G; ",,Proceedings of the International Symposium of Electronic Arts,,,,256-258,"Hoofd, Ingrid Maria; Tan, Margaret; Ying, Katharine Ho Kit",Singapore,The Inter-Society for the Electronic Arts,,978-981-08-0768-9,,,"Artificial Nature as an Infinite Game' is a trans-modal media art installation consisting of an evolutionary virtual world with a physical user interface. This virtual world is a complex, open, dynamical and dissipative system, interweaving physico-chemical, biological and symbolic strata. In actual space, spectators can witness, control and discover beautiful, generative and abstract spatio-temporal patterns evolving from the behaviors of A-life agencies in the virtual space, while the art work itself is questioning of a new understanding the concept of beauty and creativity in nature, culture and actual, virtual world.",,,2008,8,August,inproceedings,ji_2008_artificialnatureasaninfinitegame
Artificial Nature,,2009/1,Conference,"Ji, Haru; Wakefield, Graham; ",,"Proceedings of the NSF Media Arts, Science and Technology Conference",,,,,,"Santa Barbara, USA",National Science Foundation,,,,,"Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories in the production of engaging aesthetic immersive worlds. As a creative ecosystem, three virtual strata - inanimate, animate, and behavioral - truly captivate the viewer through multi-sensory interactions by drawing (touch), singing (audio), dancing (movement, visual) and navigating (movement, touch).",,,2009,1,January,inproceedings,ji_2009_artificialnature
Artificial nature: fluid space,,2009/1,Conference,"Ji, Haru; Wakefield, Graham; ",,ACM SIGGRAPH ASIA 2009 Art Gallery & Emerging Technologies: Adaptation,,,,26-26,"Tomoe Moriyama, Stephanie Choo","Yokohama, Japan",ACM,10.1145/1665137.1665153,978-1-60558-878-0,,http://dx.doi.org/10.1145/1665137.1665153,,,,2009,1,January,inproceedings,ji_2009_artificialnaturefluidspace
Computational Composition and Creativity,,2009/1,Conference,"Smith, Wesley; Wakefield, Graham; ",,"Proceedings of the NSF Media Arts, Science and Technology Conference",,,,,,"Santa Barbara, USA",National Science Foundation,,,,,"Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories in the production of engaging aesthetic immersive worlds. As a creative ecosystem, three virtual strata - inanimate, animate, and behavioral - truly captivate the viewer through multi-sensory interactions by drawing (touch), singing (audio), dancing (movement, visual) and navigating (movement, touch).",,,2009,1,January,inproceedings,smith_2009_computationalcompositionandcreativity
Artificial nature: Immersive world making,,2009/4,Conference,"Wakefield, Graham; Ji, Haru; ",,Applications of Evolutionary Computing,Theoretical Computer Science and General Issues,5484,,597-602,Mario Giacobini et al.,,"Springer, Berlin, Heidelberg",10.1007/978-3-642-01129-0,978-3-642-01128-3,http://link.springer.com/chapter/10.1007%2F978-3-642-01129-0_68,http://dx.doi.org/10.1007/978-3-642-01129-0,"Artificial Nature is a trans-disciplinary research project drawing upon bio-inspired system theories in the production of engaging immersive worlds as art installations. Embodied world making and immersion are identified as key components in an exploration of creative ecosystems toward art-as-it-could-be. A detailed account of the design of a successfully exhibited creative ecosystem is given in these terms, and open questions are outlined.",,"EvoMusArt forms part of the EvoSTAR European Workshops on Applications of Evolutionary Computation. Our paper describes an ongoing research project drawing upon bio-inspired system theories in the production of engaging immersive worlds as art installations. Embodied world making and immersion are identified as key components in an exploration of creative ecosystems toward art-as-it-could-be, and a detailed account of the design of a successfully exhibited creative ecosystem is given in these terms.",2009,4,April,inproceedings,wakefield_2009_artificialnatureimmersiveworldmaking
Artificial Nature: Research and Development,,2009/7,Conference,"Ji, Haru; Wakefield, Graham; ",,The 2nd International Conference on Media Art and Information Aesthetics (MAIA),,,,,,"Beijing, China",CAFA Art Museum Beijing China,,,,,"Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories towards engaging aesthetic world-making. Our motivation is to develop a deeper understanding of emergence and creativity as a form of art, study and play, by taking inspiration from nature's creativity while recognizing the potential of natural creation beyond the known and the physical. In this paper we trace the progression of Artificial Nature from original inspirations through diverse prototypes to elaborate immersive installations.",,,2009,7,July,inproceedings,ji_2009_artificialnatureresearchanddevelopment
Machinic / Open,,2009/7,Chapter,"Wakefield, Graham",,Machine Dreams,,,,120-123,"Jeon, Byeong-Sam; Ji, Haru","Seoul, Korea",KoIAN,,978-89-963788-0-8,,,,,,2009,7,July,incollection,wakefield_2009_machinicopen
Augmenting Computer Music with Just-In-Time Compilation,,2009/8,Conference,"Smith, Wesley; Wakefield, Graham; ",,Proceedings of the International Computer Music Conference,,,,439-442,,"Montreal, Canada",ICMA,,,http://quod.lib.umich.edu/i/icmc/bbp2372.2009.100/-augmenting-computer-music-with-just-in-time-compilation?view=image&seq=1&size=100,,We discuss the potential of just-in-time compilation for computer music software to evade compromises of flexibility and efficiency due to the discrepencies between the respective natures of composition and computation and also to augment exploratory and generative capacity. We present a range of examples and approaches using LLVM compiler infrastructure within the LuaAV composition environment and measure its performance against static compilation.,,,2009,8,August,inproceedings,smith_2009_augmentingcomputermusicwithjustintimecompilation
"The Allobrain: An interactive, stereographic, 3D audio, immersive virtual world",,2009/11,Journal,"Thompson, John; Kuchera-Morin, JoAnn; Novak, Marcos; Overholt, Dan; Putnam, Lance; Wakefield, Graham; Smith, Wesley; ",,International Journal of Human-Computer Studies,,67,11,934-946,,,Elsevier,10.1016/j.ijhcs.2009.05.005,,http://www.sciencedirect.com/science/article/pii/S1071581909000688,http://dx.doi.org/10.1016/j.ijhcs.2009.05.005,"This paper describes the creation of the Allobrain project, an interactive, stereoscopic, 3D audio, immersive virtual world constructed from fMRI brain data and installed in the Allosphere, one of the largest virtual reality spaces in existence. This paper portrays the role the Allobrain project played as an artwork driving the technological infrastructure of the Allosphere. The construction of the Cosm toolkit software for prototyping the Allobrain and other interactive, stereographic, 3D audio, immersive virtual worlds in the Allosphere is described in detail. Aesthetic considerations of the Allobrain project are discussed in relation to world-making as a means to understand and explore large data sets.",,,2009,11,November,article,thompson_2009_theallobrainaninteractivestereographic3daudioimmersivevirtualworld
LuaAV: Extensibility and heterogeneity for audiovisual computing,,2010/5,Conference,"Wakefield, Graham; Smith, Wesley; Roberts, Charles; ",,Applied Sciences,,,,31-38,Maurits Lamers,"Utrecht, the Netherlands",Hogeschool voor de Kunsten,,,,,"We describe LuaAV, a runtime library and applica- tion which extends the Lua programming language to support computational composition of temporal, sound, visual, spatial and other elements. In this paper we document how we have attempted to maintain several core principles of Lua itself - extensibility, meta-mechanisms, efficiency, portabil- ity - while providing the flexibility and temporal accuracy demanded by interactive audio-visual media. Code generation is noted as a recurrent strategy for increasingly dynamic and extensible environments.",,,2010,5,May,inproceedings,wakefield_2010_luaavextensibilityandheterogeneityforaudiovisualcomputing
Dynamic Interactivity Inside the AlloSphere,,2010/6,Conference,"Roberts, Charles; Wright, Matthew; Kuchera-Morin, JoAnn; Putnam, Lance; Wakefield, Graham; ",,Proceedings of the International Conference on New Interfaces for Musical Expression,,,,57-62,,"Sydney, Australia",,,,http://www.nime.org/wp-publications/roberts2010/,http://www.nime.org/proceedings/2010/nime2010_057.pdf,"We present the Device Server, a framework and application driving interaction in the AlloSphere virtual reality environment. The motivation and development of the Device Server stems from the practical concerns of managing multi-user interactivity with a variety of physical devices for disparate performance and virtual reality environments housed in the same physical location. The interface of the Device Server allows users to see how devices are assigned to application functionalities, alter these assignments and save them into configuration files for later use. Configurations defining how applications use devices can be changed on the fly without recompiling or relaunching applications. Multiple applications can be connected to the Device Server concurrently. The Device Server provides several conveniences for performance environments. It can process control data efficiently using Just-In-Time compiled Lua expressions; in doing so it frees processing cycles on audio and video rendering computers. All control signals entering the Device Server can be recorded, saved, and played back allowing performances based on control data to be recreated in their entirety. The Device Server attempts to homogenize the ap- pearance of different control signals to applications so that users can assign any interface element they choose to application functionalities and easily experiment with different control configurations.",,,2010,6,June,inproceedings,roberts_2010_dynamicinteractivityinsidetheallosphere
Immersed in unfolding complex systems,,2010/6,Chapter,"Putnam, Lance; Wakefield, Graham; Ji, Haru; Alper, Basak; Adderton, Dennis; Kuchera-Morin, JoAnn; ",,Beautiful Visualization: Looking at Data through the Eyes of Experts,,,,291-310,"Julie Steele, Noah Iliinsky",,"O'Reilly Media, Inc.",,,http://shop.oreilly.com/product/0636920000617.do,,,,"A chapter for a popular book series focusing on visualization, describing work by the AlloSphere Research Group at the California NanoSystems Institute, UC Santa Barbara. My contributions included the opening sections of strategy and philosophy, as well as content and software design, followed by two sections describing specific application implementations. O’Reilly Media’s “Beautiful...” book series has been very successful and widely acclaimed.",2010,6,June,incollection,putnam_2010_immersedinunfoldingcomplexsystems
COSM: A toolkit for composing immersive audio-visual worlds of agency and autonomy.,,2011/8,Conference,"Wakefield, Graham; Smith, Wesley; ",,Proceedings of the International Computer Music Conference,,,,13-20,,"Huddersfield, United Kingdom",International Computer Music Association,,,http://quod.lib.umich.edu/i/icmc/bbp2372.2011.004/-cosm-a-toolkit-for-composing-immersive-audio-visual-worlds,http://quod.lib.umich.edu/i/icmc/bbp2372.2011.004/-cosm-a-toolkit-for-composing-immersive-audio-visual-worlds,"Spatial music can create immersive experiences of alter- nate realities. To what degree can this be expanded to the composition of immersive, navigable, audio-visual worlds? We present an integrated collection of exten- sions to the Max/MSP/Jitter environment to assist the tightly integrated construction of such worlds, designed for use within audio-visual virtual environments and other projects using spatial simulation. The perspective taken is that spatial composition can go beyond the specification of locations and trajectories to the composition of auton- omy, agency and interactions.",,,2011,8,August,inproceedings,wakefield_2011_cosmatoolkitforcomposingimmersiveaudiovisualworldsofagencyandautonomy
Time of Doubles,,2011/12,Conference,"Ji, Haru; Wakefield, Graham; ",,Proceedings of SIGGRAPH ASIA Art Gallery,,,,26-26,Rochelle Yang,Hong Kong,ACM,10.1145/2077355.2425799,978-1-4503-1133-5,,http://dx.doi.org/10.1145/2077355.2425799,"Time of Doubles' is an immersive interactive art installation. It invites visitors to experience mirror existences of themselves taking upon new roles as sources of energy and kinetic disturbance within a virtual ecosystem, a uniquely created computational world. Visitors encounter their doubles in a deep hyper space with 3D stereoscopic projection and 3D depth cameras. The immersive projection dissolves the illusion of a window to form an entryway into a shared, co-present world, and the volumetric sensors take the visitors beyond avatar-based representation to become embodied within a world of physical simulation. This world displays some familiar characteristics as our own, but is populated by unfamiliar life-forms swimming through the sensitive motions of dark fluids and singing continuously. The visitor doubles are energy fields which emanate myriad bright fluid particles, food sources which are eaten by the virtual organisms. Visitors hear, see and feel how they are fed to unknown species in the virtual ecosystem aesthetically. Without visitors, the world-fluid is filled with life seeds that cannot grow, but with a human presence the populations explode into alien orchestras. Larger organisms leave physical residues and films behind as they pass, which constrain the fluid flows and which can be sculpted by visitor doubles.",,,2011,12,December,inproceedings,ji_2011_timeofdoubles
Mobile Controls On-The-Fly: An Abstraction for Distributed NIMEs,,2012/5,Conference,"Roberts, Charles; Wakefield, Graham; Wright, Matthew; ",,Proceedings of the International Conference on New Interfaces for Musical Expression,,,,,,"Ann Arbor, Michigan",University of Michigan,,,http://www.nime.org/wp-publications/roberts2012/,http://www.nime.org/proceedings/2012/nime2012_303.pdf,"Designing mobile interfaces for computer-based musical performance is generally a time-consuming task that can be exasperating for performers. Instead of being able to experiment freely with physical interfaces' affordances, performers must spend time and attention on non-musical tasks including network configuration, development environments for the mobile devices, defining OSC address spaces, and handling the receipt of OSC in the environment that will control and produce sound. Our research seeks to overcome such obstacles by minimizing the code needed to both generate and read the output of interfaces on mobile devices. For iOS and Android devices, our implementation extends the application Control to use a simple set of OSC messages to define interfaces and automatically route output. On the desktop, our implementations in Max/MSP/Jitter, LuaAV, and Su-perCollider allow users to create mobile widgets mapped to sonic parameters with a single line of code. We believe the fluidity of our approach will encourage users to incorporate mobile devices into their everyday performance practice.",,,2012,5,May,inproceedings,roberts_2012_mobilecontrolsontheflyanabstractionfordistributednimes
Real-time meta-programming for interactive computational arts,,2012/9,PhD Thesis,"Wakefield, Graham; Roberts, Charlie; Wright, Matthew; Wood, Timothy; Yerkes, Karl; ",,,,,,,"Roads, Curtis; Kuchera-Morin, JoAnn; Novak, Marcos; Wright, Matthew","Santa Barbara, USA",University of California Santa Barbara,,,,,"In the interactive computer arts, any advance that significantly amplifies or extends the limits and capacities of software can enable genuinely novel aesthetic experiences. Within compute-intensive media arts, flexibility is often sacrificed for needs of efficiency, through the total separation of machine code optimization and run-time execution. Compromises based on modular run-time combinations of prior-optimized `black box' components confine results to a pre-defined palette with less computational efficiency overall: limiting the open-endedness of development environments and the generative scope of artworks. This dissertation demonstrates how the trade-off between flexibility and efficiency can be relaxed using reflective meta-programming and dynamic compilation: extending a pro- gram with new efficient routines while it runs. It promises benefits of more open- ended real-time systems, more complex algorithms, richer media, and ultimately unprecedented aesthetic experiences. The dissertation charts the significant differences that this approach implies for interactive computational arts, builds a conceptual framework of techniques and requirements to respond to its challenges, and documents supporting implementations in two specific scenarios. The first concentrates on open-ended creativity support within always-on authoring environments for studio work and live cod- ing performance, while the second concerns the open-endedness of generative art through interactive, immersive artificial-life worlds.",,"My doctoral research focused on run-time code generation and dynamic compilation for interactive computational arts.  Run-time code generation opens up a vast possibility space for execution flow, valuable both for creative sketching and authoring environments, as well as artificial life and other generative systems. Dynamic compilation can ensure the efficiency of generated code in real-time scenarios, however it has been hitherto only rarely utilized in computational arts. The theoretical framework presented in the first half of the dissertation is evaluated in the context of its application in authoring environments and interactive artworks. One such application is the Gen extension to Max/MSP/Jitter, which extends a well-known visual data-flow programming environment for audio to support efficient single-sample feedback, with novel capabilities for filter design, physical modeling etc. Gen was released as a commercial product in 2011 and has now tens of thousands of users, and has been the basis of several graduate-level courses (unrelated to the author). A second application integrates into the author’s “Time of Doubles” interactive artwork, in which populations of thousands of organisms continuously interact with users, metabolizing and reproducing on time-scales of seconds. Using code generation and dynamic compilation, each newly born organism embeds a uniquely generated, evolved piece of machine code, allowing a much greater space of behavior without compromising population size. This version of the artwork has been successfully exhibited at three international events since 2011. (Separate publications of the project contributions are in progress.)",2012,9,September,phdthesis,wakefield_2012_realtimemetaprogrammingforinteractivecomputationalarts
Virtual world-making in an interactive art installation: Time of doubles,,2012/11,Chapter,"Ji, Haru; Wakefield, G; ",,Virtual worlds,,,,53-70,"Stephan Bornhofen, Jean-Claude Heudin, Alain Lioret, Jean-Claude Torrel","Paris, France",Science eBook,,979-10-91245-06-7,http://www.science-ebook.fr/bonus/virtual_worlds_extrait.pdf,http://www.science-ebook.fr/bonus/virtual_worlds_extrait.pdf,"Time of Doubles is an immersive, interactive art installation, and an instantiation of contemporary art research on the creation of possible worlds. It invites visitors to experience mirror existences of themselves taking upon new roles as sources of energy and kinetic disturbance within a perpetually changing virtual ecosystem. This world displays some characteristics familiar from our own, but is populated by unfamiliar life forms singing, swimming, and breeding through sensitive motions of dark fluids. The visitors' doubles are energy fields, which emanate myriad bright fluid particles, food sources to be eaten by the virtual organisms. Visitors see, hear, and feel how they are fed to unknown species in this virtual ecosystem. The immersive multimodal environment and volumetric sensors take the visitors beyond avatar-based interaction to become embodied within a world of physical and biological activity. The installation has been presented in gallery settings and CAVE-like environments utilizing 3D depth cameras, stereographic display and surround audio. As an immersive audio-visual installation, it brings forth a world of aesthetic play through the embodiment of complex multi-layered and inter-modulating systems. In this paper, the artists describe Time of Doubles from its conceptual foundations, developmental process and installation construction.",Representative chapter.,,2012,11,November,incollection,ji_2012_virtualworldmakinginaninteractiveartinstallationtimeofdoubles
The Web Browser As Synthesizer And Interface,,2013/5,Conference,"Roberts, Charles; Wakefield, Graham; Wright, Matthew; ",,Proceedings of SIGGRAPH ASIA Art Gallery,,,,313-318,Kyogu Lee,"Daejeon, Republic of Korea","Graduate School of Culture Technology, KAIST",,,http://nime.org/proceedings/2013/nime2013_282.pdf,http://nime.org/proceedings/2013/nime2013_282.pdf,"Web technologies provide an incredible opportunity to present new musicalinterfaces to new audiences. Applications written in JavaScript and designed torun in the browser offer remarkable performance, mobile/desktop portability andlongevity due to standardization. Our research examines the use and potentialof native web technologies for musical expression. We introduce two libraries towards this end: Gibberish.js, a heavily optimized audio DSP library, and Interface.js, a GUI toolkit that works with mouse, touch and motion events.Together these libraries provide a complete system for defining musicalinstruments that can be used in both desktop and mobile browsers. Interface.jsalso enables control of remote synthesis applications by including an application that translates the socket protocol used by browsers into both MIDI and OSC messages.",Awarded best paper.,"NIME is the foremost conference for human-computer interaction in a musical context. NIME 2013 was notably marked by the increased interest and research using new web technologies for interactive audio synthesis, mobile device interaction, multi-user server apps and live-coding. Our paper presented results in all these areas through the gibberish.js and interface.js libraries, leveraging code generation to support optimized single-sample feedback, and automatic web interface generation. It was selected as best paper of the conference, was expanded in Computer Music Journal (MIT Press), and will be reprinted with additional commentary in The NIME Reader.",2013,5,May,inproceedings,roberts_2013_thewebbrowserassynthesizerandinterface
Becoming-There: Natural Presence in an Art of Artificial Ecologies,,2013/7,Conference,"Wakefield, Graham; Ji, Haru; ",,International Symposium on Ubiquitous Virtual Reality,,,,11-14,,"Daejeon, Republic of Korea",IEEE,10.1109/ISUVR.2013.14,978-0-7695-5084-8,http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6597723,http://dx.doi.org/10.1109/ISUVR.2013.14,"A discussion of the theoretical perspectives on immersion, presence and agency in VR and HCI research, with a new application to large-scale interactive, generative artworks. The task-centric approach common to VR HCI research may be inappropriate to encompass the inclusivity and open-endedness of art experience; however several aspects of presence and agency ('being together', 'being able to do') are found to have direct relevance. A new mode of presence concerning our relationship with a simulated biological environment is proposed.",Keynote paper.,,2013,7,July,inproceedings,wakefield_2013_becomingtherenaturalpresenceinanartofartificialecologies
Spatial Interaction in a Multiuser Immersive Instrument,,2013/11,Journal,"Wakefield, Graham; Hollerer, Tobias; Kuchera-Morin, JoAnn; Roberts, Charles; Wright, Matthew; ",,IEEE Computer Graphics and Applications,,33,6,14-20,,,IEEE,,,http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6682950,http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6682950,The AlloSphere provides multiuser spatial interaction through a curved surround screen and surround sound. Two projects illustrate how researchers employed the AlloSphere to investigate the combined use of personal-device displays and the shared display. Another two projects combined multiuser interaction with multiagent systems. These projects point to directions for future ensemble-style collaborative interaction.,,,2013,11,November,article,wakefield_2013_spatialinteractioninamultiuserimmersiveinstrument
Immersive full-surround multi-user system design,,2014/5,Journal,"Kuchera-Morin, JoAnn; Wright, Matthew; Wakefield, Graham; Roberts, Charles; Adderton, Dennis; Sajadi, Behzad; Höllerer, Tobias; Majumder, Aditi; ",,Computers & Graphics,,40,,10-21,,,Pergamon,10.1016/j.cag.2013.12.004,,http://www.sciencedirect.com/science/article/pii/S0097849314000090,http://dx.doi.org/10.1016/j.cag.2013.12.004,"This paper describes our research in full-surround, multimodal, multi-user, immersive instrument design in a large VR instrument. The three-story instrument, designed for large-scale, multimodal representation of complex and potentially high-dimensional information, specifically focuses on multi-user participation by facilitating interdisciplinary teams of co-located researchers in exploring complex information through interactive visual and aural displays in a full-surround, immersive environment. We recently achieved several milestones in the instrument's design that improves multi-user participation when exploring complex data representations and scientific simulations. These milestones include affordances for 'ensemble-style' interaction allowing groups of participants to see, hear, and explore data as a team using our multi-user tracking and interaction systems; separate visual display modes for rectangular legacy content and for seamless surround-view stereoscopic projection using 4 high-resolution, high-lumen projectors with hardware warping and blending integrated with 22 small-footprint projectors placed above and below the instrument's walkway; and a 3D spatial audio system enabling a variety of sound spatialization techniques. These facilities can be accessed and controlled by a multimodal framework for authoring applications integrating visual, audio, and interactive elements. We report on the achieved instrument design.",,,2014,5,May,article,kuchera-morin_2014_immersivefullsurroundmultiusersystemdesign
Poetry of Separation: The Aesthetics of Spatial Montage and Generative Editing for Multi-layered Screens,,2014/5,Conference,"Bahng, So Jung; Yoo, Doo Won; Hutchings, Patrick; Shi, Chung Kon; Wakefield, Graham; ","Bahng, So Jung and Hutchings, Patrick",International Conference on Arts and Technology,Lecture Notes of the Institute for Computer Sciences: Social Informatics and Telecommunications Engineering,145,,61-68,,"Istanbul, Turkey","Springer, Cham",10.1007/978-3-319-18836-2_8,978-3-319-18835-5,http://link.springer.com/chapter/10.1007/978-3-319-18836-2_8,http://link.springer.com/chapter/10.1007/978-3-319-18836-2_8,"`Poetry of Separation' is a media artwork that utilizes an algorithmic generative editing system, selecting shots in real-time to be rendered over four screens arranged in layers. Editing in cinema reconstructs images by montage, deriving meaning from the juxtaposition of multiple shots. Although multi-screen projections have been used to present sectional montages that stress the simultaneity of events, spatially separated screens can disrupt attentiveness and affective involvement; the layered architecture avoids disruptive fragmentation. The generative editing system selects shots for the layered screens stochastically, with authorial constraints and probabilities using pre-determined shot criteria. Narrative flow and authorial intents are not damaged due to these criteria, but nevertheless unexpected effects arose from the stochastic system. The authorial intentions of improvisation and separation in the film content of `Poetry of Separations' find resonance with the automatism of the generative editing system and multi-dimensionality of the screens.",,,2014,5,May,inproceedings,bahng_2014_poetryofseparationtheaestheticsofspatialmontageandgenerativeeditingformultilayeredscreens
AiRSculpt: A Wearable Augmented Reality 3D Sculpting System,,2014/6,Conference,"Jang, Sung-A; Kim, Hyung-il; Woo, Woontack; Wakefield, Graham; ","Jang, Sung-A",International Symposium on Ubiquitous Virtual Reality,Lecture Notes in Computer Science,8530,,130-141,,"Heraklion, Crete, Greece",Springer International Publishing,10.1007/978-3-319-07788-8_13,978-3-319-07787-1,http://link.springer.com/chapter/10.1007%2F978-3-319-07788-8_13#page-1,http://dx.doi.org/10.1007/978-3-319-07788-8_13,"In this paper, we present a new kind of wearable augmented reality (AR) 3D sculpting system called AiRSculpt in which users could directly translate their fluid finger movements in air into expressive sculptural forms and use hand gestures to navigate the interface. In AiRSculpt, as opposed to VR-based systems, users could quickly create and manipulate 3D virtual content directly with their bare hands in a real-world setting, and use both hands simultaneously in tandem or as separate tools to sculpt and manipulate their virtual creations. Our system uses a head-mounted display and a RGB-D head-mounted camera to detect the 3D location of hands and fingertips then render virtual content in calibration with real-world coordinates.",,,2014,6,June,inproceedings,jang_2014_airsculptawearableaugmentedreality3dsculptingsystem
Collaborative Live-Coding Virtual Worlds with an Immersive Instrument,,2014/6,Conference,"Wakefield, Graham; Roberts, Charlie; Wright, Matthew; Wood, Timothy; Yerkes, Karl; ",,Proceedings of New Instruments for Musical Expression (NIME).,,,,505-508,,"London, United Kingdom",Goldsmiths College University of London,,,http://nime2014.org/proceedings/papers/328_paper.pdf,http://www.nime.org/proceedings/2014/nime2014_328.pdf,"We discuss live coding audio-visual worlds for large-scale virtual reality environments. We describe Alive, an instrument allowing multiple users to develop sonic and visual behaviors of agents in a virtual world, through a browser based collaborative code interface, accessible while being immersed through spatialized audio and stereoscopic display. The interface adds terse syntax for query-based precise or stochastic selections and declarative agent manipulations, lazily-evaluated expressions for synthesis and behavior, event handling, and flexible scheduling.",,,2014,6,June,inproceedings,wakefield_2014_collaborativelivecodingvirtualworldswithanimmersiveinstrument
Digital Love Letter: A Handwriting Based Interface for Non-instant Digital Messenger,,2014/6,Conference,"Bang, So Jung; Song, Yoonji; Kim, Jae Dong; Suh, Kiseul; Shi, Chung-Kon; Wakefield, Graham; Woo, Sungju; ","Bahng, So Jung and Hutchings, Patrick",International Conference on Human-Computer Interaction: Applications and Services,Lecture Notes in Computer Science,8512,,103-113,,"Heraklion, Crete, Greece","Springer, Cham",10.1007/978-3-319-07227-2_11,978-3-319-07226-5,,http://dx.doi.org/10.1007/978-3-319-07227-2_11,"The instant messenger has developed as an important communication media platform. However, because of the nature of instant communication, instant messenger services place many limitations on communicating with nuance. We believe that the easy nature of digital communications tends to weaken serious aspects of personal communication such as patience and commitment. On the basis of critical perspectives, we designed the digital messenger `Digital Love Letter' (DLL)': a mobile messenger in which the expressive process of interaction is more important than the final output. The main concept of DLL is to share the process of communication using a non-instantaneous and non-multitasking interface, so that users can share their time with some similar nuances to face-to-face communication. Both writing and reading messages require concentrated attention. Thus, this paper suggests a new system of digital messenger, that is also a new method of computer-mediated communication (CMC).",,,2014,6,June,inproceedings,bang_2014_digitalloveletterahandwritingbasedinterfacefornoninstantdigitalmessenger
Designing musical instruments for the browser,,2015/3,Journal,"Roberts, Charles; Wakefield, Graham; Wright, Matthew; Kuchera-Morin, JoAnn; ",,Computer Music Journal,,39,1,27-40,,,MITP,10.1162/COMJ_a_00283,,http://www.mitpressjournals.org/doi/abs/10.1162/COMJ_a_00283#.VkL35tBkflc,http://dx.doi.org/10.1162/COMJ_a_00283,"Native Web technologies provide great potential for musical expression. We introduce two JavaScript libraries towards this end: Gibberish.js, providing heavily optimized audio DSP, and Interface.js, a GUI toolkit that works with mouse, touch, and motion events. Together they provide a complete system for defining musical instruments that can be used in both desktop and mobile Web browsers. Interface.js also enables control of remote synthesis applications via a server application that translates the socket protocol used by Web interfaces into both MIDI and OSC messages. We have incorporated these libraries into the creative coding environment Gibber, where we provide mapping abstractions that enable users to create digital musical instruments in as little as a single line of code. They can then be published to a central database, enabling new instruments to be created, distributed, and run entirely in the browser.",,,2015,3,March,article,roberts_2015_designingmusicalinstrumentsforthebrowser
"Generative spatial montage with multi-layered screens in ""Lost Fragments of Night""",,2015/3,Conference,"Bahng, Sojung; Hutchings, Patrick; Yoo, Doo Won; Shi, Chung Kon; Wakefield, Graham; ","Bahng, So Jung and Hutchings, Patrick",International Symposium on Electronic Arts,,,,,"Brad Moody, Marta Ameri, Thorsten Lomker",Dubai,,,,,,"`Lost Fragments of Night' is a poetic documentary film that utilizes an algorithmic generative editing system to preselect shots to be rendered over four screens arranged in layers. The artwork's subject is the chaotic and contradictory sensations found by night in the city of Seoul. In this work, the themes of disconnected and paradoxical images in urban public spaces resonate with the concepts of the multi-layered screens and generative editing system. The fragmented images are distributed over layers of screens to emphasize a chaotic and simultaneous sense of fragility that nevertheless together forms a whole. Designed for large-scale installation in urban public spaces, our artwork has been prototyped via a physical miniature, projecting by rear diffusion onto four layered screens constructed of grey sheer fabric. The audience can appreciate the montage from different angles and positions to produce different layering effects not possible in traditional 2D cinema. The generative editing system uses a dynamic Bayesian network constructed according to clips and timeline tagging. Audience members can actively contribute to the direction of the montage through a web interface, so the artwork creates different experiences by embracing the role of the audience in every screening.",,,2015,3,March,inproceedings,bahng_2015_generativespatialmontagewithmultilayeredscreensinlostfragmentsofnight
Toward Certain Sonic Properties of an Audio Feedback System by Evolutionary Control of Second-Order Structures,,2015/4,Conference,"Kim, Seunghun; Nam, Juhan; Wakefield, Graham; ","Kim, Seunghun",International Conference on Evolutionary and Biologically Inspired Music and Art,Lecture Notes in Computer Science,9027,,113-124,,"Copenhagen, Denmark","Springer, Cham",10.1007/978-3-319-16498-4_11,978-3-319-16497-7,http://link.springer.com/chapter/10.1007%2F978-3-319-16498-4_11,http://dx.doi.org/10.1007/978-3-319-16498-4_11,"Aiming for high-level intentional control of audio feedback, though microphones, loudspeakers and digital signal processing, we present a system adapting toward chosen sonic features. Users control the system by selecting and changing feature objectives in real-time. The system has a second-order structure in which the internal signal processing algorithms are developed according to an evolutionary process. Genotypes develop into signal-processing algorithms, and fitness is measured by analysis of the incoming audio feedback. A prototype is evaluated experimentally to measure changes of audio feedback depending on the chosen target conditions. By enhancing interactivity of an audio feedback through the intentional control, we expect that feedback systems could be utilized more effectively in the fields of musical interaction, finding balance between nonlinearity and interactivity.",,,2015,4,April,inproceedings,kim_2015_towardcertainsonicpropertiesofanaudiofeedbacksystembyevolutionarycontrolofsecondorderstructures
Augmenting Room Acoustics and System Interaction for Intentional Control of Audio Feedback,,2015/10,Conference,"Kim, Seunghun; Wakefield, Graham; Nam, Juhan; ","Kim, Seunghun",Proceedings of the International Computer Music Conference,,,,,,"Denton, Texas, USA",University of North Texas,,,,,"This paper presents the interactive enhancement of audio feedback through context-based control, leading to the generation of desired sonic behaviors by augmenting the effects of physical space in the feedback sound. Our prototype maps approximations of room reverberation to tempo-scale characteristics of the audio feedback. These characteristics are generated by a combination of adaptive amplification control and a digital variable delay line in the feedback loop. Room reverberation is inferred from the feedback sound by real-time cross-correlation of input with output signals, which is used to guide the variable delay line. This variation, coupled with an adaptive gain control, determines room-dependent tempo effects.",,,2015,10,October,inproceedings,kim_2015_augmentingroomacousticsandsysteminteractionforintentionalcontrolofaudiofeedback
Endogenous biologically-inspired visualization immersed within an art of complex systems.,,2015/10,Conference,"Ji, Haru; Wakefield, Graham; ",,IEEE VIS Arts Program (VISAP),,,,30-37,"Angus Forbes, Fanny Chevalier, Daria Tsoupikova","Chicago, USA","Chicago, Illinois",,,http://visap.uic.edu/2015/VISAP15-Papers/visap2015_Ji_BiologicallyInspired.pdf,,"We document techniques and insights gained through the creation of interactive visualizations of biologically-inspired complex systems that have been exhibited as mixed-reality art installations since 2007. A binding theme is the importance of endogenous accounts: that all perceivable forms have dynamic ontological capacities within the world; that the simulated world is able to autonomously originate; that as a result interaction can lead to exploratory discovery; and that visitors become part of the ecosystem, both through immersive display and through interactions that induce presence. Details of how each of these components have been applied in the visualization, sonification, and interaction design are given with specific examples of prototypes and exhibited installations.",,,2015,10,October,inproceedings,ji_2015_endogenousbiologicallyinspiredvisualizationimmersedwithinanartofcomplexsystems
Endogenous biologically inspired art of complex systems,,2016/1,Journal,"Ji, Haru; Wakefield, Graham; ",,IEEE Computer Graphics and Applications,Computer Graphics and Applications,36,1,16-21,,,IEEE Computer Society,,,https://www.computer.org/csdl/mags/cg/2016/01/mcg2016010016-abs.html,,,,,2016,1,January,article,ji_2016_endogenousbiologicallyinspiredartofcomplexsystems
Augmenting Environmental Interaction in Audio Feedback Systems,,2016/4,Journal,"Kim, Seunghun; Wakefield, Graham; Nam, Juhan; ","Kim, Seunghun",Applied Sciences,,6,5,125-139,,,Multidisciplinary Digital Publishing Institute,10.3390/app6050125,,,,"Audio feedback is defined as a positive feedback of acoustic signals where an audio input and output form a loop, and may be utilized artistically. This article presents new context-based controls over audio feedback, leading to the generation of desired sonic behaviors by enriching the influence of existing acoustic information such as room response and ambient noise. This ecological approach to audio feedback emphasizes mutual sonic interaction between signal processing and the acoustic environment. Mappings from analyses of the received signal to signal-processing parameters are designed to emphasize this specificity as an aesthetic goal. Our feedback system presents four types of mappings: approximate analyses of room reverberation to tempo-scale characteristics, ambient noise to amplitude and two different approximations of resonances to timbre. These mappings are validated computationally and evaluated experimentally in different acoustic conditions.",,,2016,4,April,article,kim_2016_augmentingenvironmentalinteractioninaudiofeedbacksystems
Sonic Participation in the Evolving Audio Feedback System,,2016/5,Conference,"Kim, Seunghun; Oh, Changheun, Wakefield, Graham; Nam, Juhan","Kim, Seunghun",Proceeedings of the 22nd International Symposium on Electronic Art,,,,,,Hong Kong,ISEA International,,,,,,,,2016,5,May,inproceedings,kim_2016_sonicparticipationintheevolvingaudiofeedbacksystem
Live Coding the Digital Audio Workstation,,2016/10,Conference,"Roberts, Charles; Wakefield, Graham; ",,Proceedings of the 2nd International Conference on Live Coding,,,,,,"Hamilton, Canada",McMaster University,,,,,,,,2016,10,October,inproceedings,roberts_2016_livecodingthedigitalaudioworkstation
Recent Realizations of Artificial Nature,,2016/11,Chapter,"Ji, Haru; Wakefield, Graham; ",,Living Architecture Systems Group White Papers,,,,197-206,,"Waterloo, Canada",Riverside Architectural Press,,,,,"Since 2007 the authors have been pursuing a line of research-creation that utilizes installations of highly-immersive mixed reality and interactive generative art to investigate new relationships with a future that is increasingly immersed in computation, but which draws more inspiration from the complex sense of open-ended continuation found in nature than any closed character of utilitarian closure. This project has produced in a series of 'artificial natures', whose installations account for over thirty-five exhibits across nine countries. These are proposed as viscerally-experienced explorations of the physical and cultural future of near-living interconnected architectural environments saturated in computational media. In this white paper the central concerns of the artificial nature project are illustrated with three examples, including ancillary contributions and key questions for the future.",,,2016,11,November,incollection,ji_2016_recentrealizationsofartificialnature
A Virtual Machine for Live Coding Language Design,,2017/5,Conference,"Wakefield, Graham; Roberts, Charles; ",,Proceedings of the New interfaces for Musical Expression Conference,,,,,,"Copenhagen, Denmark",,,,,,,,,2017,5,May,inproceedings,wakefield_2017_avirtualmachineforlivecodinglanguagedesign
gibberwocky: New Live-Coding Instruments for Musical Performance,,2017/5,Conference,"Roberts, Charles; Wakefield, Graham; ",,Proceedings of the International Conference on New Interfaces for Musical Expression,,,,,,"Copenhagen, Denmark",,,,,,,,,2017,5,May,inproceedings,roberts_2017_gibberwockynewlivecodinginstrumentsformusicalperformance
Incorporating Kinesthetic Creativity and Gestural Play into Immersive Modeling,,2017/6,Conference,"Jang, Sung-A; Wakefield, Graham; Lee, Sung-Hee; ","Jang, Sung-A",Proceedings of the 4th International Conference on Movement Computing,,,,17-24,,"London, United Kingdom",ACM,10.1145/3077981.3078045,,https://dl.acm.org/citation.cfm?id=3078045,,,,,2017,6,June,inproceedings,jang_2017_incorporatingkinestheticcreativityandgesturalplayintoimmersivemodeling
Biotopes Numériques (Computational Biotopes),X,2017/12,Chapter,"Ji, Haru; Wakefield, Graham; ",,Le Paradigme du Vivant (The Paradigm of Living Systems),Stream,4,,,,"Paris, France",Philippe Chiambaretta Architecte,,,,,,,,2017,12,December,incollection,ji_2017_biotopesnumriquescomputationalbiotopes
2013: The Web Browser as Synthesizer and Interface,X,2018/1,Chapter,"Roberts, Charles; Wakefield, Graham; Wright, Matthew; ",,A NIME Reader,,,,433-450,,,Springer International Publishing,,,,,,,,2018,1,January,incollection,roberts_2018_2013thewebbrowserassynthesizerandinterface
Open Worlds: Bergson And Computational Ontology,X,2018/1,Chapter,"Wakefield, Graham",,"Worldmaking as Techné: Exploring Worlds of Participatory Art, Architecture, and Music",,,,,"Hosale, Mark-David; Murrani, Sana; de Campo, Alberto","Waterloo, Canada",Riverside Architectural Press,,,,,"These are exciting times for world-makers. Widely-available virtual worlds, whether fully immersive virtual realities, or mixed realities that blend with or augment the real, at last appear to be imminent. This path of worldmaking is suddenly widely-backed, affordable, and accessible, with eager anticipation far beyond the catalytic space of videogames including art, design, film, architecture, information visualization, and more. It bears all the hallmarks of the birth of a new medium. The conventions have yet to be frozen, the genres crystallized, the messages of the medium deciphered. And inevitably it is being understood through a McLuhanian rear-view mirror: projecting old game tropes awkwardly into new spaces, and struggling with the loss of the frame, the cut, and the directed view of cinema. Rather than extrapolating forward from the familiar in this way, as world-makers we would rather find a path to a reach speculative goal: a creative ontology that opens upon the vast creative poiesis that the generative grains of computation make possible, making worlds that approach the open-endedness of the natural reality we inhabit, including its endless capacity to change and reveal surprisingly new and fascinating phenomena. To this end we revive the nature-inspired creative philosophy of Henri Bergson, and address the challenges and potentials of re-projecting it into interactive computational media, to illuminate a way forward.",,"A peer-reviewed collection connecting theory and practice (techné) with the ontologies of interactive worlds, catalyzed by a panel discussion at the Inter-Society of Electronic Arts (ISEA) conference 2011. My chapter analyzes the challenge of creating systems that continually recreate themselves in an open-ended manner; a core problem for generative art, artificial life, and responsive environments. My contribution leverages the oft-misunderstood creative philosophy of Henri Bergson, reconciling it with computation through interactive, self-modifying and rewriting systems.",2018,1,January,incollection,wakefield_2018_openworldsbergsonandcomputationalontology
Tensions and Techniques in Live Coding Performance,X,2018/1,Chapter,"Roberts, Charles; Wakefield, Graham",,The Oxford Handbook of Algorithmic Music,,,,,"Dean, Roger; McLean, Alex","Oxford, United Kingdom",Oxford University Press,,,,,"A review of live coding techniques building upon algorithmic descriptions of musical pattern and sound synthesis, to explore how algorithms are made and improvised with, with focus on the temporal relationship between performer, their algorithm and their performance.",,"Peer review back for the Oxford Handbook on Algorithmic Music, concludes that it 'deserves the reputation of being the goto book on algorithmic music in general and the trending wave of live coding in particular.'",2018,1,January,incollection,roberts_2018_tensionsandtechniquesinlivecodingperformance
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!
,,,,,,,,,,,,,,,,,,,,,1899,12,December,article,#VALUE!