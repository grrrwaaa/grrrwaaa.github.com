bibtex_entrytype,bibtex_id,status,title,author,editor,year,booktitle,publisher,abstract,commentary,generated_authorlist,generated_editorlist,month,journal,volume,generated_monthname,pages,DOI,URL,venue,number,trainee,voluome,BDSK-URL-1,ISBN,BDSK-URL-2,annote,address,school
"incollection","wakefield2016open","In press","Open Worlds: Bergson And Computational Ontology","[object Object]","[object Object],[object Object],[object Object]","2018","Worldmaking as Techn&eacute;: Exploring Worlds of Participatory Art, Architecture, and Music","Riverside Architectural Press","These are exciting times for world-makers. Widely-available virtual worlds, whether fully immersive virtual realities, or mixed realities that blend with or augment the real, at last appear to be imminent. This path of worldmaking is suddenly widely-backed, affordable, and accessible, with eager anticipation far beyond the catalytic space of videogames including art, design, film, architecture, information visualization, and more. It bears all the hallmarks of the birth of a new medium. The conventions have yet to be frozen, the genres crystallized, the messages of the medium deciphered. And inevitably it is being understood through a McLuhanian rear-view mirror: projecting old game tropes awkwardly into new spaces, and struggling with the loss of the frame, the cut, and the directed view of cinema. Rather than extrapolating forward from the familiar in this way, as world-makers we would rather find a path to a reach speculative goal: a creative ontology that opens upon the vast creative poiesis that the generative grains of computation make possible, making worlds that approach the open-endedness of the natural reality we inhabit, including its endless capacity to change and reveal surprisingly new and fascinating phenomena. To this end we revive the nature-inspired creative philosophy of Henri Bergson, and address the challenges and potentials of re-projecting it into interactive computational media, to illuminate a way forward.","A peer-reviewed collection connecting theory and practice (techné) with the ontologies of interactive worlds, catalyzed by a panel discussion at the Inter-Society of Electronic Arts (ISEA) conference 2011. My chapter analyzes the challenge of creating systems that continually recreate themselves in an open-ended manner; a core problem for generative art, artificial life, and responsive environments. My contribution leverages the oft-misunderstood creative philosophy of Henri Bergson, reconciling it with computation through interactive, self-modifying and rewriting systems.","Graham Wakefield","Alberto de Campo, Mark-David Hosale, Sana Murrani","","","","","","","","","","","","","","","","",""
"incollection","ji2017stream","In press","Biotopes Numériques (Computational Biotopes)","[object Object],[object Object]","","2017","Le Paradigme du Vivant (The Paradigm of Living Systems)","Philippe Chiambaretta Architecte","","","Haru (Hyunkyung) Ji, Graham Wakefield","","11","Stream","4","November","","","","","","","","","","","","",""
"incollection","ji2016recent","In press","Recent Realizations of Artificial Nature","[object Object],[object Object]","","2016","Living Architecture Systems Group White Papers","Riverside Architectural Press","Since 2007 the authors have been pursuing a line of research-creation that utilizes installations of highly-immersive mixed reality and interactive generative art to investigate new relationships with a future that is increasingly immersed in computation, but which draws more inspiration from the complex sense of open-ended continuation found in nature than any closed character of utilitarian closure. This project has produced in a series of 'artificial natures', whose installations account for over thirty-five exhibits across nine countries. These are proposed as viscerally-experienced explorations of the physical and cultural future of near-living interconnected architectural environments saturated in computational media. In this white paper the central concerns of the artificial nature project are illustrated with three examples, including ancillary contributions and key questions for the future.","","Haru (Hyunkyung) Ji, Graham Wakefield","","","","","","","","","","","","","","","","","",""
"incollection","roberts2016tensions","In press","Tensions &amp; Techniques in Live Coding Performance","[object Object],[object Object]","[object Object],[object Object]","2016","The Oxford Handbook of Algorithmic Music","Oxford University Press","A review of live coding techniques building upon algorithmic descriptions of musical pattern and sound synthesis, to explore how algorithms are made and improvised with, with focus on the temporal relationship between performer, their algorithm and their performance.","Peer review back for the Oxford Handbook on Algorithmic Music, concludes that it 'deserves the reputation of being the goto book on algorithmic music in general and the trending wave of live coding in particular.'","Charles Roberts, Graham Wakefield","Roger Dean, Alex McLean","","","","","","","","","","","","","","","","",""
"inproceedings","jang2017moco","","Incorporating Kinesthetic Creativity and Gestural Play into Immersive Modeling","[object Object],[object Object],[object Object]","","2017","Proceedings of the 4th International Conference on Motion Computing","ACM","","","Sung-A Jang, Graham Wakefield, Sung-Hee Lee","","6","","","June","17-24","10.1145/3077981.3078045","https://dl.acm.org/citation.cfm?id=3078045","London, United Kingdom","","","","","","","","",""
"inproceedings","roberts2016livecoding","","Live Coding the Digital Audio Workstation","[object Object],[object Object]","","2016","Proceedings of the International Conference on Live Coding","","","","Charles Roberts, Graham Wakefield","","10","","","October","","","","Hamilton, Canada","","","","","","","","",""
"article","kim2016augmenting","","Augmenting Environmental Interaction in Audio Feedback Systems","[object Object],[object Object],[object Object]","","2016","","","","","Seunghun Kim, Graham Wakefield, Juhan Nam","","5","Applied Sciences","6","May","125","","","","5","","","","","","","",""
"article","ji2016endogenous","","Endogenous Biologically Inspired Art of Complex Systems","[object Object],[object Object]","","2016","","IEEE Computer Society","","","Haru (Hyunkyung) Ji, Graham Wakefield","","1","Computer Graphics and Applications","36","January","16-21","","https://www.computer.org/csdl/mags/cg/2016/01/mcg2016010016-abs.html","","1","","","","","","","",""
"inproceedings","kim2016sonic","","Sonic Participation in the Evolving Audio Feedback System","[object Object],[object Object],[object Object],[object Object]","","2016","Proceedings of the International Symposium of Electronic Art","","","","Seunghun Kim, Changheun Oh, Graham Wakefield, Juhan Nam","","","","","","","","","Hong Kong","","Kim, Seunghun","","","","","","",""
"inproceedings","ji2015endogenous","","Endogenous Biologically-Inspired Visualization Immersed Within an Art of Complex Systems","[object Object],[object Object]","[object Object],[object Object],[object Object]","2015","Proceedings of the IEEE VIS Arts Program","University of Illinois at Chicago","We document techniques and insights gained through the creation of interactive visualizations of biologically-inspired complex systems that have been exhibited as mixed-reality art installations since 2007. A binding theme is the importance of endogenous accounts: that all perceivable forms have dynamic ontological capacities within the world; that the simulated world is able to autonomously originate; that as a result interaction can lead to exploratory discovery; and that visitors become part of the ecosystem, both through immersive display and through interactions that induce presence. Details of how each of these components have been applied in the visualization, sonification, and interaction design are given with specific examples of prototypes and exhibited installations.","","Haru (Hyunkyung) Ji, Graham Wakefield","Angus Forbes, Fanny Chevalier, Daria Tsoupikova","10","","","October","30-37","","http://visap.uic.edu/2015/VISAP15-Papers/visap2015_Ji_BiologicallyInspired.pdf","Chicago, USA","","","","","","","","",""
"inproceedings","kim2015augmenting","","Augmenting Room Acoustics and System Interaction for Intentional Control of Audio Feedback","[object Object],[object Object],[object Object]","","2015","Proceedings of the International Computer Music Conference","University of North Texas","This paper presents the interactive enhancement of audio feedback through context-based control, leading to the generation of desired sonic behaviors by augmenting the effects of physical space in the feedback sound. Our prototype maps approximations of room reverberation to tempo-scale characteristics of the audio feedback. These characteristics are generated by a combination of adaptive amplification control and a digital variable delay line in the feedback loop. Room reverberation is inferred from the feedback sound by real-time cross-correlation of input with output signals, which is used to guide the variable delay line. This variation, coupled with an adaptive gain control, determines room-dependent tempo effects.","","Seunghun Kim, Graham Wakefield, Juhan Nam","","9","","","September","","","","Denton, USA","","Kim, Seunghun","","","","","","",""
"article","roberts2015designing","","Designing Musical Instruments for the Browser","[object Object],[object Object],[object Object],[object Object]","","2015","","MIT Press","Native Web technologies provide great potential for musical expression. We introduce two JavaScript libraries towards this end: Gibberish.js, providing heavily optimized audio DSP, and Interface.js, a GUI toolkit that works with mouse, touch, and motion events. Together they provide a complete system for defining musical instruments that can be used in both desktop and mobile Web browsers. Interface.js also enables control of remote synthesis applications via a server application that translates the socket protocol used by Web interfaces into both MIDI and OSC messages. We have incorporated these libraries into the creative coding environment Gibber, where we provide mapping abstractions that enable users to create digital musical instruments in as little as a single line of code. They can then be published to a central database, enabling new instruments to be created, distributed, and run entirely in the browser.","","Charles Roberts, Graham Wakefield, Matthew Wright, JoAnn Kuchera-Morin","","3","Computer Music Journal","","March","27-40","10.1162/COMJ_a_00283","http://www.mitpressjournals.org/doi/abs/10.1162/COMJ_a_00283#.VkL35tBkflc","","1","","39","http://dx.doi.org/10.1162/COMJ_a_00283","","","","",""
"incollection","kim2015toward","","Toward Certain Sonic Properties of an Audio Feedback System by Evolutionary Control of Second-Order Structures","[object Object],[object Object],[object Object]","","2015","Evolutionary and Biologically Inspired Music, Sound, Art and Design","Springer International Publishing","Aiming for high-level intentional control of audio feedback, though microphones, loudspeakers and digital signal processing, we present a system adapting toward chosen sonic features. Users control the system by selecting and changing feature objectives in real-time. The system has a second-order structure in which the internal signal processing algorithms are developed according to an evolutionary process. Genotypes develop into signal-processing algorithms, and fitness is measured by analysis of the incoming audio feedback. A prototype is evaluated experimentally to measure changes of audio feedback depending on the chosen target conditions. By enhancing interactivity of an audio feedback through the intentional control, we expect that feedback systems could be utilized more effectively in the fields of musical interaction, finding balance between nonlinearity and interactivity.","","Seunghun Kim, Juhan Nam, Graham Wakefield","","[object Object]","Lecture Notes in Computer Science","9027","","113-124","10.1007/978-3-319-16498-4_11","http://link.springer.com/chapter/10.1007%2F978-3-319-16498-4_11","The 4th International Conference EvoMUSART, Copenhagen","","Kim, Seunghun","","http://dx.doi.org/10.1007/978-3-319-16498-4_11","978-3-319-16497-7","","","",""
"inproceedings","bang2014lost","","Generative Spatial Montage with Multi-Layered Screens in 'Lost Fragments of Night'","[object Object],[object Object],[object Object],[object Object]","[object Object],[object Object],[object Object]","2014","Proceedings of the International Symposium on Electronic Arts","The Inter-Society for the Electronic Arts","`Lost Fragments of Night' is a poetic documentary film that utilizes an algorithmic generative editing system to preselect shots to be rendered over four screens arranged in layers. The artwork's subject is the chaotic and contradictory sensations found by night in the city of Seoul. In this work, the themes of disconnected and paradoxical images in urban public spaces resonate with the concepts of the multi-layered screens and generative editing system. The fragmented images are distributed over layers of screens to emphasize a chaotic and simultaneous sense of fragility that nevertheless together forms a whole. Designed for large-scale installation in urban public spaces, our artwork has been prototyped via a physical miniature, projecting by rear diffusion onto four layered screens constructed of grey sheer fabric. The audience can appreciate the montage from different angles and positions to produce different layering effects not possible in traditional 2D cinema. The generative editing system uses a dynamic Bayesian network constructed according to clips and timeline tagging. Audience members can actively contribute to the direction of the montage through a web interface, so the artwork creates different experiences by embracing the role of the audience in every screening.","","So Jung Bahng, Patrick Hutchings, Yoo Doo Won, Graham Wakefield","Brad Moody, Marta Ameri, Thorsten Lomker","10","","","October","","","","Dubai","","Bahng, So Jung and Hutchings, Patrick","","","","","","",""
"incollection","jang2014airsculpt","","AiRSculpt: A Wearable Augmented Reality 3D Sculpting System","[object Object],[object Object],[object Object],[object Object]","","2014","Distributed, Ambient, and Pervasive Interactions","Springer International Publishing","In this paper, we present a new kind of wearable augmented reality (AR) 3D sculpting system called AiRSculpt in which users could directly translate their fluid finger movements in air into expressive sculptural forms and use hand gestures to navigate the interface. In AiRSculpt, as opposed to VR-based systems, users could quickly create and manipulate 3D virtual content directly with their bare hands in a real-world setting, and use both hands simultaneously in tandem or as separate tools to sculpt and manipulate their virtual creations. Our system uses a head-mounted display and a RGB-D head-mounted camera to detect the 3D location of hands and fingertips then render virtual content in calibration with real-world coordinates.","","Sung-A Jang, Hyung-il Kim, Woontack Woo, Graham Wakefield","","6","Lecture Notes in Computer Science","8530","June","130-141","10.1007/978-3-319-07788-8_13","http://link.springer.com/chapter/10.1007%2F978-3-319-07788-8_13#page-1","HCI Interational, Heraklion, Crete, Greece","","Jang, Sung-A","","http://dx.doi.org/10.1007/978-3-319-07788-8_13","978-3-319-07787-1","","","",""
"incollection","bahng2014digital","","Digital Love Letter: A Handwriting Based Interface for Non-instant Digital Messenger","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","","2014","Human-Computer Interaction. Applications and Services","Springer International Publishing","The instant messenger has developed as an important communication media platform. However, because of the nature of instant communication, instant messenger services place many limitations on communicating with nuance. We believe that the easy nature of digital communications tends to weaken serious aspects of personal communication such as patience and commitment. On the basis of critical perspectives, we designed the digital messenger `Digital Love Letter' (DLL)': a mobile messenger in which the expressive process of interaction is more important than the final output. The main concept of DLL is to share the process of communication using a non-instantaneous and non-multitasking interface, so that users can share their time with some similar nuances to face-to-face communication. Both writing and reading messages require concentrated attention. Thus, this paper suggests a new system of digital messenger, that is also a new method of computer-mediated communication (CMC).","","So Jung Bahng, Yoonji Song, Jae Dong Kim, Kiseul Suh, Chung-Kon Shi, Graham Wakefield, Sungju Woo","","6","Lecture Notes in Computer Science","8512","June","103-113","10.1007/978-3-319-07227-2_11","","HCI International, Heraklion, Crete, Greece","","Bahng, So Jung and Hutchings, Patrick","","http://dx.doi.org/10.1007/978-3-319-07227-2_11","978-3-319-07226-5","","","",""
"inproceedings","wakefield2014collaborative","","Collaborative Live-Coding with an Immersive Instrument","[object Object],[object Object],[object Object],[object Object],[object Object]","","2014","Proceedings of the International Conference on New Interfaces for Musical Expression","Goldsmiths, University of London","We discuss live coding audio-visual worlds for large-scale virtual reality environments. We describe Alive, an instrument allowing multiple users to develop sonic and visual behaviors of agents in a virtual world, through a browser based collaborative code interface, accessible while being immersed through spatialized audio and stereoscopic display. The interface adds terse syntax for query-based precise or stochastic selections and declarative agent manipulations, lazily-evaluated expressions for synthesis and behavior, event handling, and flexible scheduling.","","Graham Wakefield, Charles Roberts, Matthew Wright, Timothy Wood, Karl Yerkes","","6","","","June","505-508","","http://nime2014.org/proceedings/papers/328_paper.pdf","London, United Kingdom","","","","http://www.nime.org/proceedings/2014/nime2014_328.pdf","","","","",""
"article","kuchera2014immersive","","Immersive full-surround multi-user system design","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","","2014","","Elsevier","This paper describes our research in full-surround, multimodal, multi-user, immersive instrument design in a large VR instrument. The three-story instrument, designed for large-scale, multimodal representation of complex and potentially high-dimensional information, specifically focuses on multi-user participation by facilitating interdisciplinary teams of co-located researchers in exploring complex information through interactive visual and aural displays in a full-surround, immersive environment. We recently achieved several milestones in the instrument's design that improves multi-user participation when exploring complex data representations and scientific simulations. These milestones include affordances for 'ensemble-style' interaction allowing groups of participants to see, hear, and explore data as a team using our multi-user tracking and interaction systems; separate visual display modes for rectangular legacy content and for seamless surround-view stereoscopic projection using 4 high-resolution, high-lumen projectors with hardware warping and blending integrated with 22 small-footprint projectors placed above and below the instrument's walkway; and a 3D spatial audio system enabling a variety of sound spatialization techniques. These facilities can be accessed and controlled by a multimodal framework for authoring applications integrating visual, audio, and interactive elements. We report on the achieved instrument design.","","JoAnn Kuchera-Morin, Matthew Wright, Graham Wakefield, Charles Roberts, Dennis Adderton, Behzad Sajadi, Tobias H&ouml;llerer, Aditi Majumder","","5","Computers &amp; Graphics","40","May","10-21","10.1016/j.cag.2013.12.004","http://www.sciencedirect.com/science/article/pii/S0097849314000090","","","","","http://www.sciencedirect.com/science/article/pii/S0097849314000090","","http://dx.doi.org/10.1016/j.cag.2013.12.004","","",""
"incollection","bahng2014poetry","","Poetry of Separation: The Aesthetics of Spatial Montage and Generative Editing for Multi-layered Screens","[object Object],[object Object],[object Object],[object Object],[object Object]","","2014","Arts and Technology","Springer International Publishing","`Poetry of Separation' is a media artwork that utilizes an algorithmic generative editing system, selecting shots in real-time to be rendered over four screens arranged in layers. Editing in cinema reconstructs images by montage, deriving meaning from the juxtaposition of multiple shots. Although multi-screen projections have been used to present sectional montages that stress the simultaneity of events, spatially separated screens can disrupt attentiveness and affective involvement; the layered architecture avoids disruptive fragmentation. The generative editing system selects shots for the layered screens stochastically, with authorial constraints and probabilities using pre-determined shot criteria. Narrative flow and authorial intents are not damaged due to these criteria, but nevertheless unexpected effects arose from the stochastic system. The authorial intentions of improvisation and separation in the film content of `Poetry of Separations' find resonance with the automatism of the generative editing system and multi-dimensionality of the screens.","","So Jung Bahng, Doo Won Yoo, Patrick Hutchings, Chung Kon Shi, Graham Wakefield","","5","Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering","145","May","61-68","10.1007/978-3-319-18836-2_8","http://link.springer.com/chapter/10.1007/978-3-319-18836-2_8","Fourth International Conference, ArtsIT, Istanbul, Turkey","","Bahng, So Jung and Hutchings, Patrick","","http://link.springer.com/chapter/10.1007/978-3-319-18836-2_8","978-3-319-18835-5","http://dx.doi.org/10.1007/978-3-319-18836-2_8","","",""
"article","wakefield2013spatial","","Spatial Interaction in a Multiuser Immersive Instrument","[object Object],[object Object],[object Object],[object Object],[object Object]","","2013","","IEEE Computer Society","The AlloSphere provides multiuser spatial interaction through a curved surround screen and surround sound. Two projects illustrate how researchers employed the AlloSphere to investigate the combined use of personal-device displays and the shared display. Another two projects combined multiuser interaction with multiagent systems. These projects point to directions for future ensemble-style collaborative interaction.","","Graham Wakefield, Tobias H&ouml;llerer, JoAnn Kuchera-Morin, Charles Roberts, Matthew Wright","","11","Computer Graphics and Applications","33","November","14-20","","http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6682950","","6","","","http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6682950","","","","",""
"inproceedings","wakefield2013becoming","","Becoming-There: Natural Presence in an Art of Artificial Ecologies","[object Object],[object Object]","","2013","International Symposium on Ubiquitous Virtual Reality","IEEE Computer Society","A discussion of the theoretical perspectives on immersion, presence and agency in VR and HCI research, with a new application to large-scale interactive, generative artworks. The task-centric approach common to VR HCI research may be inappropriate to encompass the inclusivity and open-endedness of art experience; however several aspects of presence and agency ('being together', 'being able to do') are found to have direct relevance. A new mode of presence concerning our relationship with a simulated biological environment is proposed.","","Graham Wakefield, Haru (Hyunkyung) Ji","","7","","","July","11-14","10.1109/ISUVR.2013.14","http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6597723","Daejeon, Republic of Korea","","","","http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6597723","978-0-7695-5084-8","http://dx.doi.org/10.1109/ISUVR.2013.14","Keynote paper.","",""
"inproceedings","roberts2013web","","The web browser as synthesizer and interface","[object Object],[object Object],[object Object]","[object Object]","2013","Proceedings of the International Conference on New Interfaces for Musical Expression","Graduate School of Culture Technology, KAIST","Web technologies provide an incredible opportunity to present new musicalinterfaces to new audiences. Applications written in JavaScript and designed torun in the browser offer remarkable performance, mobile/desktop portability andlongevity due to standardization. Our research examines the use and potentialof native web technologies for musical expression. We introduce two libraries towards this end: Gibberish.js, a heavily optimized audio DSP library, and Interface.js, a GUI toolkit that works with mouse, touch and motion events.Together these libraries provide a complete system for defining musicalinstruments that can be used in both desktop and mobile browsers. Interface.jsalso enables control of remote synthesis applications by including an application that translates the socket protocol used by browsers into both MIDI and OSC messages.","NIME is the foremost conference for human-computer interaction in a musical context. NIME 2013 was notably marked by the increased interest and research using new web technologies for interactive audio synthesis, mobile device interaction, multi-user server apps and live-coding. Our paper presented results in all these areas through the gibberish.js and interface.js libraries, leveraging code generation to support optimized single-sample feedback, and automatic web interface generation. It was selected as best paper of the conference, was expanded in Computer Music Journal (MIT Press), and will be reprinted with additional commentary in The NIME Reader.","Charles Roberts, Graham Wakefield, Matthew Wright","Kyogu Lee","5","","","May","313-318","","http://nime.org/proceedings/2013/nime2013_282.pdf","Daejeon, Republic of Korea","","","","http://nime.org/proceedings/2013/nime2013_282.pdf","","","Awarded best paper.","",""
"incollection","wakefield2012virtual","","Virtual World-Making in an Interactive Art Installation: Time of Doubles","[object Object],[object Object]","[object Object],[object Object],[object Object],[object Object]","2012","Virtual Worlds","Science eBook, Paris","Time of Doubles is an immersive, interactive art installation, and an instantiation of contemporary art research on the creation of possible worlds. It invites visitors to experience mirror existences of themselves taking upon new roles as sources of energy and kinetic disturbance within a perpetually changing virtual ecosystem. This world displays some characteristics familiar from our own, but is populated by unfamiliar life forms singing, swimming, and breeding through sensitive motions of dark fluids. The visitors' doubles are energy fields, which emanate myriad bright fluid particles, food sources to be eaten by the virtual organisms. Visitors see, hear, and feel how they are fed to unknown species in this virtual ecosystem. The immersive multimodal environment and volumetric sensors take the visitors beyond avatar-based interaction to become embodied within a world of physical and biological activity. The installation has been presented in gallery settings and CAVE-like environments utilizing 3D depth cameras, stereographic display and surround audio. As an immersive audio-visual installation, it brings forth a world of aesthetic play through the embodiment of complex multi-layered and inter-modulating systems. In this paper, the artists describe Time of Doubles from its conceptual foundations, developmental process and installation construction.","","Graham Wakefield, Haru (Hyunkyung) Ji","Stephan Bornhofen, Jean-Claude Heudin, Alain Lioret, Jean-Claude Torrel","11","","","November","","","http://www.science-ebook.fr/bonus/virtual_worlds_extrait.pdf","","","","","http://www.science-ebook.fr/bonus/virtual_worlds_extrait.pdf","979-10-91245-06-7","","Representative chapter.","",""
"phdthesis","wakefield2012phdthesis","","Real-Time Meta-Programming for Interactive Computational Arts","[object Object]","","2012","","","In the interactive computer arts, any advance that significantly amplifies or extends the limits and capacities of software can enable genuinely novel aesthetic experiences. Within compute-intensive media arts, flexibility is often sacrificed for needs of efficiency, through the total separation of machine code optimization and run-time execution. Compromises based on modular run-time combinations of prior-optimized `black box' components confine results to a pre-defined palette with less computational efficiency overall: limiting the open-endedness of development environments and the generative scope of artworks. This dissertation demonstrates how the trade-off between flexibility and efficiency can be relaxed using reflective meta-programming and dynamic compilation: extending a pro- gram with new efficient routines while it runs. It promises benefits of more open- ended real-time systems, more complex algorithms, richer media, and ultimately unprecedented aesthetic experiences. The dissertation charts the significant differences that this approach implies for interactive computational arts, builds a conceptual framework of techniques and requirements to respond to its challenges, and documents supporting implementations in two specific scenarios. The first concentrates on open-ended creativity support within always-on authoring environments for studio work and live cod- ing performance, while the second concerns the open-endedness of generative art through interactive, immersive artificial-life worlds.","My doctoral research focused on run-time code generation and dynamic compilation for interactive computational arts.  Run-time code generation opens up a vast possibility space for execution flow, valuable both for creative sketching and authoring environments, as well as artificial life and other generative systems. Dynamic compilation can ensure the efficiency of generated code in real-time scenarios, however it has been hitherto only rarely utilized in computational arts. The theoretical framework presented in the first half of the dissertation is evaluated in the context of its application in authoring environments and interactive artworks. One such application is the Gen extension to Max/MSP/Jitter, which extends a well-known visual data-flow programming environment for audio to support efficient single-sample feedback, with novel capabilities for filter design, physical modeling etc. Gen was released as a commercial product in 2011 and has now tens of thousands of users, and has been the basis of several graduate-level courses (unrelated to the author). A second application integrates into the author’s “Time of Doubles” interactive artwork, in which populations of thousands of organisms continuously interact with users, metabolizing and reproducing on time-scales of seconds. Using code generation and dynamic compilation, each newly born organism embeds a uniquely generated, evolved piece of machine code, allowing a much greater space of behavior without compromising population size. This version of the artwork has been successfully exhibited at three international events since 2011. (Separate publications of the project contributions are in progress.)","Graham Wakefield","","9","","","September","","","","","","","","","","","","Santa Barbara, USA","University of California Santa Barbara"
"inproceedings","roberts2012mobile","","Mobile Controls On-The-Fly: An Abstraction for Distributed NIMEs","[object Object],[object Object],[object Object]","","2012","Proceedings of the International Conference on New Interfaces for Musical Expression","University of Michigan","Designing mobile interfaces for computer-based musical performance is generally a time-consuming task that can be exasperating for performers. Instead of being able to experiment freely with physical interfaces' affordances, performers must spend time and attention on non-musical tasks including network configuration, development environments for the mobile devices, defining OSC address spaces, and handling the receipt of OSC in the environment that will control and produce sound. Our research seeks to overcome such obstacles by minimizing the code needed to both generate and read the output of interfaces on mobile devices. For iOS and Android devices, our implementation extends the application Control to use a simple set of OSC messages to define interfaces and automatically route output. On the desktop, our implementations in Max/MSP/Jitter, LuaAV, and Su-perCollider allow users to create mobile widgets mapped to sonic parameters with a single line of code. We believe the fluidity of our approach will encourage users to incorporate mobile devices into their everyday performance practice.","","Charles Roberts, Graham Wakefield, Matthew Wright","","","","","","","","http://www.nime.org/wp-publications/roberts2012/","Ann Arbor, Michigan","","","","http://www.nime.org/proceedings/2012/nime2012_303.pdf","","","","",""
"inproceedings","ji2011time","","Time of Doubles","[object Object],[object Object]","[object Object]","2011","Proceedings of SIGGRAPH ASIA Art Gallery","ACM","'Time of Doubles' is an immersive interactive art installation. It invites visitors to experience mirror existences of themselves taking upon new roles as sources of energy and kinetic disturbance within a virtual ecosystem, a uniquely created computational world. Visitors encounter their doubles in a deep hyper space with 3D stereoscopic projection and 3D depth cameras. The immersive projection dissolves the illusion of a window to form an entryway into a shared, co-present world, and the volumetric sensors take the visitors beyond avatar-based representation to become embodied within a world of physical simulation. This world displays some familiar characteristics as our own, but is populated by unfamiliar life-forms swimming through the sensitive motions of dark fluids and singing continuously. The visitor doubles are energy fields which emanate myriad bright fluid particles, food sources which are eaten by the virtual organisms. Visitors hear, see and feel how they are fed to unknown species in the virtual ecosystem aesthetically. Without visitors, the world-fluid is filled with life seeds that cannot grow, but with a human presence the populations explode into alien orchestras. Larger organisms leave physical residues and films behind as they pass, which constrain the fluid flows and which can be sculpted by visitor doubles.","","Haru (Hyunkyung) Ji, Graham Wakefield","Rochelle Yang","12","","","December","26-26","10.1145/2077355.2425799","","Hong Kong","","","","http://dx.doi.org/10.1145/2077355.2425799","978-1-4503-1133-5","","","",""
"inproceedings","wakefield2011cosm","","Cosm: A toolkit for composing immersive audio-visual worlds of agency and autonomy","[object Object],[object Object]","","2011","Proceedings of the International Computer Music Conference","ICMA","Spatial music can create immersive experiences of alter- nate realities. To what degree can this be expanded to the composition of immersive, navigable, audio-visual worlds? We present an integrated collection of exten- sions to the Max/MSP/Jitter environment to assist the tightly integrated construction of such worlds, designed for use within audio-visual virtual environments and other projects using spatial simulation. The perspective taken is that spatial composition can go beyond the specification of locations and trajectories to the composition of auton- omy, agency and interactions.","","Graham Wakefield, Wesley Smith","","7","","","July","13-20","","http://quod.lib.umich.edu/i/icmc/bbp2372.2011.004/-cosm-a-toolkit-for-composing-immersive-audio-visual-worlds","Huddersfield, UK","","","","http://quod.lib.umich.edu/i/icmc/bbp2372.2011.004/-cosm-a-toolkit-for-composing-immersive-audio-visual-worlds","","","","",""
"incollection","putnam2010immersed","","Immersed in Unfolding Complex Systems","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","[object Object],[object Object]","2010","Beautiful Visualization: Looking at Data through the Eyes of Experts","O'Reilly Media, Inc.","","A chapter for a popular book series focusing on visualization, describing work by the AlloSphere Research Group at the California NanoSystems Institute, UC Santa Barbara. My contributions included the opening sections of strategy and philosophy, as well as content and software design, followed by two sections describing specific application implementations. O’Reilly Media’s “Beautiful...” book series has been very successful and widely acclaimed.","Lance Putnam, Graham Wakefield, Haru (Hyunkyung) Ji, Basak Alper, Dennis Adderton, JoAnn Kuchera-Morin","Julie Steele, Noah Iliinsky","","","","","291-310","","http://shop.oreilly.com/product/0636920000617.do","","","","","","","","","",""
"inproceedings","roberts2010dynamic","","Dynamic Interactivity inside the AlloSphere","[object Object],[object Object],[object Object],[object Object],[object Object]","","2010","Proceedings of the International Conference on New Interfaces for Musical Expression (NIME)","","We present the Device Server, a framework and application driving interaction in the AlloSphere virtual reality environment. The motivation and development of the Device Server stems from the practical concerns of managing multi-user interactivity with a variety of physical devices for disparate performance and virtual reality environments housed in the same physical location. The interface of the Device Server allows users to see how devices are assigned to application functionalities, alter these assignments and save them into configuration files for later use. Configurations defining how applications use devices can be changed on the fly without recompiling or relaunching applications. Multiple applications can be connected to the Device Server concurrently. The Device Server provides several conveniences for performance environments. It can process control data efficiently using Just-In-Time compiled Lua expressions; in doing so it frees processing cycles on audio and video rendering computers. All control signals entering the Device Server can be recorded, saved, and played back allowing performances based on control data to be recreated in their entirety. The Device Server attempts to homogenize the ap- pearance of different control signals to applications so that users can assign any interface element they choose to application functionalities and easily experiment with different control configurations.","","Charles Roberts, Matthew Wright, JoAnn Kuchera-Morin, Lance Putnam, Graham Wakefield","","6","","","June","57-62","","http://www.nime.org/wp-publications/roberts2010/","Sydney, Australia","","","","http://www.nime.org/proceedings/2010/nime2010_057.pdf","","","","",""
"inproceedings","wakefield2010luaav","","LuaAV: Extensibility and heterogeneity for audiovisual computing","[object Object],[object Object],[object Object]","[object Object]","2010","Proceedings of the Linux Audio Conference","Hogeschool voor de Kunsten","We describe LuaAV, a runtime library and applica- tion which extends the Lua programming language to support computational composition of temporal, sound, visual, spatial and other elements. In this paper we document how we have attempted to maintain several core principles of Lua itself - extensibility, meta-mechanisms, efficiency, portabil- ity - while providing the flexibility and temporal accuracy demanded by interactive audio-visual media. Code generation is noted as a recurrent strategy for increasingly dynamic and extensible environments.","","Graham Wakefield, Wesley Smith, Charles Roberts","Maurits Lamers","5","","","May","31-38","","","Utrecht, the Netherlands","","","","","","","","",""
"article","thompson2009allobrain","","The Allobrain: An Interactive, Stereoscopic, 3D Audio, Immersive Virtual World","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","","2009","","Elsevier","This paper describes the creation of the Allobrain project, an interactive, stereoscopic, 3D audio, immersive virtual world constructed from fMRI brain data and installed in the Allosphere, one of the largest virtual reality spaces in existence. This paper portrays the role the Allobrain project played as an artwork driving the technological infrastructure of the Allosphere. The construction of the Cosm toolkit software for prototyping the Allobrain and other interactive, stereographic, 3D audio, immersive virtual worlds in the Allosphere is described in detail. Aesthetic considerations of the Allobrain project are discussed in relation to world-making as a means to understand and explore large data sets.","","John Thompson, JoAnn Kuchera-Morin, Marcos Novak, Dan Overholt, Lance Putnam, Graham Wakefield, Wesley Smith","","","International Journal of Human-Computer Studies","67","","934-946","10.1016/j.ijhcs.2009.05.005","http://www.sciencedirect.com/science/article/pii/S1071581909000688","","11","","","http://dx.doi.org/10.1016/j.ijhcs.2009.05.005","","","","",""
"inproceedings","ji2009fluid","","Artificial Nature: Fluid Space","[object Object],[object Object]","[object Object],[object Object]","2009","Proceedings of SIGGRAPH ASIA Art Gallery & Emerging Technologies: Adaptation","ACM","","","Haru (Hyunkyung) Ji, Graham Wakefield","Tomoe Moriyama, Stephanie Choo","12","","","December","26-26","10.1145/1665137.1665153","","Yokohama, Japan","","","","http://dx.doi.org/10.1145/1665137.1665153","978-1-60558-878-0","","","",""
"incollection","wakefield2009artificial","","Artificial nature: Immersive world making","[object Object],[object Object]","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","2009","Applications of Evolutionary Computing","Springer-Verlag Berlin Heidelberg","Artificial Nature is a trans-disciplinary research project drawing upon bio-inspired system theories in the production of engaging immersive worlds as art installations. Embodied world making and immersion are identified as key components in an exploration of creative ecosystems toward art-as-it-could-be. A detailed account of the design of a successfully exhibited creative ecosystem is given in these terms, and open questions are outlined.","EvoMusArt forms part of the EvoSTAR European Workshops on Applications of Evolutionary Computation. Our paper describes an ongoing research project drawing upon bio-inspired system theories in the production of engaging immersive worlds as art installations. Embodied world making and immersion are identified as key components in an exploration of creative ecosystems toward art-as-it-could-be, and a detailed account of the design of a successfully exhibited creative ecosystem is given in these terms.","Graham Wakefield, Haru (Hyunkyung) Ji","Mario Giacobini et al.","","Theoretical Computer Science and General Issues","5484","","597-602","10.1007/978-3-642-01129-0","http://link.springer.com/chapter/10.1007%2F978-3-642-01129-0_68","The Evolutionary Music and Art Workshop, T&uuml;bingen","","","","http://dx.doi.org/10.1007/978-3-642-01129-0","978-3-642-01128-3","","","",""
"incollection","smith2009computational","","Computational Composition and Creativity","[object Object],[object Object]","","2009","Proceedings of the NSF Media Arts, Science and Technology Conference","National Science Foundation","Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories in the production of engaging aesthetic immersive worlds. As a creative ecosystem, three virtual strata - inanimate, animate, and behavioral - truly captivate the viewer through multi-sensory interactions by drawing (touch), singing (audio), dancing (movement, visual) and navigating (movement, touch).","","Wesley Smith, Graham Wakefield","","","","","","","","","Santa Barbara, USA","","","","","","","","",""
"incollection","wakefield2009machinic","","Makeshift, Machinic / Open","[object Object]","[object Object],[object Object]","2009","Machine Dreams","KoIAN","","","Graham Wakefield","Byeong Sam Jeon, Haru (Hyunkyung) Ji","","","","","120-123","","","Seoul, Republic of Korea","","","","","978-89-963788-0-8","","","",""
"inproceedings","ji2009artificial","","Artificial Nature","[object Object],[object Object]","","2009","Proceedings of the NSF Media Arts, Science and Technology Conference","National Science Foundation","Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories in the production of engaging aesthetic immersive worlds. As a creative ecosystem, three virtual strata - inanimate, animate, and behavioral - truly captivate the viewer through multi-sensory interactions by drawing (touch), singing (audio), dancing (movement, visual) and navigating (movement, touch).","","Haru (Hyunkyung) Ji, Graham Wakefield","","","","","","","","","Santa Barbara, USA","","","","","","","","",""
"inproceedings","smith2009augmenting","","Augmenting Computer Music with Just-In-Time Compilation","[object Object],[object Object]","","2009","Proceedings of the International Computer Music Conference","ICMA","We discuss the potential of just-in-time compilation for computer music software to evade compromises of flexibility and efficiency due to the discrepencies between the respective natures of composition and computation and also to augment exploratory and generative capacity. We present a range of examples and approaches using LLVM compiler infrastructure within the LuaAV composition environment and measure its performance against static compilation.","","Wesley Smith, Graham Wakefield","","8","","","August","439-442","","http://quod.lib.umich.edu/i/icmc/bbp2372.2009.100/-augmenting-computer-music-with-just-in-time-compilation?view=image&seq=1&size=100","Montreal, Canada","","","","","","","","",""
"inproceedings","ji2009artificialrandd","","Artificial Nature: Research and Development","[object Object],[object Object]","","2009","The 2nd International Conference on Media Art and Information Aesthetics","CAFA Art Museum","Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories towards engaging aesthetic world-making. Our motivation is to develop a deeper understanding of emergence and creativity as a form of art, study and play, by taking inspiration from nature's creativity while recognizing the potential of natural creation beyond the known and the physical. In this paper we trace the progression of Artificial Nature from original inspirations through diverse prototypes to elaborate immersive installations.","","Haru (Hyunkyung) Ji, Graham Wakefield","","7","","","July","","","","Beijing, China","","","","","","","","",""
"incollection","smith2008computational","","Computational Audiovisual Composition using Lua","[object Object],[object Object]","[object Object],[object Object],[object Object]","2008","Transdisciplinary Digital Art. Sound, Vision and the New Screen","Springer-Verlag Berlin Heidelberg","We describe extensions to the Lua programming language constituting a novel platform to support practice and investigation in computational audiovisual composition. Significantly, these extensions enable the tight real-time integration of computation, time, sound and space, and follow a modus operandi of development going back to immanent properties of the domain.","","Wesley Smith, Graham Wakefield","Randy Adams, Steve Gibson, Stefan M&uuml;ller Arisona","","Communications in Computer and Information Science","7","","213-228","10.1007/978-3-540-79486-8","http://link.springer.com/chapter/10.1007/978-3-540-79486-8_19","","","","","http://dx.doi.org/10.1007/978-3-540-79486-8","978-3-540-79486-8","","","",""
"incollection","amatriain2008experiencing","","Experiencing Audio and Music in a Fully Immersive Environment","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","[object Object],[object Object],[object Object]","2008","Computer Music Modeling and Retrieval. Sense of Sounds","Springer","The UCSB Allosphere is a 3-story-high spherical instrument in which virtual environments and performances can be experienced in full immersion. The space is now being equipped with high-resolution active stereo projectors, a 3D sound system with several hundred speakers, and with tracking and interaction mechanisms. The Allosphere is at the same time multimodal, multimedia, multi-user, immersive, and interactive. This novel and unique instrument will be used for research into scientific visualization/auralization and data exploration, and as a research environment for behavioral and cognitive scientists. It will also serve as a research and performance space for artists exploring new forms of art. In particular, the Allosphere has been carefully designed to allow for immersive music and aural applications. In this paper, we give an overview of the instrument, focusing on the audio subsystem. We give the rationale behind some of the design decisions and explain the different techniques employed in making the Allosphere a truly general-purpose immersive audiovisual lab and stage. Finally, we present first results and our experiences in developing and using the Allosphere in several prototype projects.","","Xavier Amatriain, Jorge Castellanos, Tobias H&ouml;llerer, JoAnn Kuchera-Morin, Stephen T Pope, Graham Wakefield, Will Wolcott","Richard Kronland-Martinet, S&oslashlvi Ystad, Kristoffer Jensen","","Information Systems and Applications","4969","","380-400","10.1007/978-3-540-85035-9","http://link.springer.com/chapter/10.1007%2F978-3-540-85035-9_27","","","","","http://dx.doi.org/10.1007/978-3-540-85035-9","978-3-540-85034-2","","","",""
"inproceedings","ji2008artificial","","Artificial Nature as an Infinite Game","[object Object],[object Object]","[object Object],[object Object],[object Object]","2008","Proceedings of the International Symposium of Electronic Arts","The Inter-Society for the Electronic Arts","'Artificial Nature as an Infinite Game' is a trans-modal media art installation consisting of an evolutionary virtual world with a physical user interface. This virtual world is a complex, open, dynamical and dissipative system, interweaving physico-chemical, biological and symbolic strata. In actual space, spectators can witness, control and discover beautiful, generative and abstract spatio-temporal patterns evolving from the behaviors of A-life agencies in the virtual space, while the art work itself is questioning of a new understanding the concept of beauty and creativity in nature, culture and actual, virtual world.","","Haru (Hyunkyung) Ji, Graham Wakefield","Ingrid Maria Hoofd, Margaret Tan, Katharine Ho Kit Ying","8","","","August","256-258","","","Singapore","","","","","978-981-08-0768-9","","","",""
"article","zwick2008instructional","","Instructional Tools in Educational Measurement and Statistics (ITEMS) for School Personnel: Evaluation of Three Web-Based Training Modules","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","","2008","","Wiley Online Library","","","Rebecca Zwick, Jeffrey C Sklar, Graham Wakefield, Cris Hamilton, Alex Norman, Douglas Folsom","","","Educational Measurement: Issues and Practice","27","","14-27","","","","2","","","","","","","",""
"inproceedings","ji2008artificialasia","","Artificial Nature as an Infinite Game","[object Object],[object Object]","","2008","Proceedings of ASIAGRAPH","ASIAGRAPH","A virtual embodiment of an auto-creative world: generative, interactive transmodal media art installation bringing forth an ecosystem of creativity through a meshwork of strata (geo-, chemo-, bio-, sono-), re-questioning the meanings and relationships of nature, culture, life and beauty.","","Haru (Hyunkyung) Ji, Graham Wakefield","","7","","","July","","","","Shanghai, China","","","","","","","","",""
"inproceedings","wakefield2008allobrain","","The AlloBrain: an Interactive Stereoscopic, 3D Audio Immersive Environment","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object],[object Object]","2008","Proceedings of the CHI Conference Workshop on Sonic Interaction Design (SID-CHI)","ACM","This document describes the AlloBrain, the debut content created for presentation in the AlloSphere at the University of California, Santa Barbara, and the Cosm toolkit for the prototyping of interactive immersive environments using higher-order Ambisonics and stereoscopic projections. The Cosm toolkit was developed in order to support the prototyping of immersive applications that involve both visual and sonic interaction design. Design considerations and implementation details of both the Cosm toolkit and the AlloBrain are described in detail, as well as the development of custom human-computer interfaces and new audiovisual interaction methodologies within a virtual environment.","The article introduces the first project created for the CNSI AlloSphere at UC Santa Barbara (a 3-storey spherical CAVE-like environment), which provides an interactive, navigable world visualizing and sonifying fMRI brain data, of which I was the primary implementor. The article was extended for the International Journal of Human Computer Studies.","Graham Wakefield, JoAnn Kuchera-Morin, Marcos Novak, Dan Overholt, Lance Putnam, John Thompson, Wesley Smith","Davide Rocchesso et al.","4","","","April","","","","Florenz, Italy","","","","","978-1-60558-012-8/08/04","","","",""
"inproceedings","wakefield2007real","","Using Lua for Audiovisual Composition","[object Object],[object Object]","","2007","Proceedings of the International Computer Music Conference","ICMA","In this paper, we present new opportunities to overcome some of the inherent limitations of a visual data-flow environment such as Max/MSP/Jitter, by using domain specific (audio and graphical) extensions of the Lua programming language as libraries (externals). Lua is flexible, extensible and efficient, making it an ideal choice for designing a programmatic interface for multimedia composition.","","Graham Wakefield, Wesley Smith","","8","","","August","341-344","","","Copenhagen, Denmark","","","","","","","","",""
"inproceedings","smith2007real","","Real-time Multimedia Composition using Lua","[object Object],[object Object]","[object Object]","2007","Proceedings of the Digital Art Weeks","Digital Art Weeks International","In this paper, we present a new interface for programming multimedia compositions in Max/ MSP/Jitter using the Lua scripting language. Lua is extensible and efficient making it an ideal choice for designing a programmatic interface for multimedia compositions. First, we discuss the distinctions of graphical and textual interfaces for composition and the requirements for a productive compositional workflow, and then we describe domain specific implementations of Lua bindings as Max externals for graphics and audio in that order.","","Wesley Smith, Graham Wakefield","Stefan M&uuml;ller Arisona","7","","","July","","","","Zurich, Switzerland","","","","","","","","",""
"mastersthesis","wakefield2007mastersthesis","","Vessel: A Platform for Computer Music Composition, Interleaving Sample-Accurate Synthesis and Control","[object Object]","","2007","","","The rich new terrains offered by computer music invite the exploration of new techniques to compose within them. The computational nature of the medium has suggested algorithmic approaches to composition in the form of generative musical structure at the note level and above, and audio signal processing at the level of individual samples. In the region between these levels, the domain of microsound, we may wish to investigate the musical potential of sonic particles that interrelate both signal processing and generative structure. In this thesis I present a software platform (`Vessel') for the exploration of such potential. In particular, a solution to the efficient scheduling of interleaved sound synthesis and algorithmic control with sample accuracy is expounded. The formal foundations, design and implementation are described, the project is contrasted with existing work, and avenues for musical application and future exploration are proposed.","","Graham Wakefield","","6","","","June","","","http://www.mat.ucsb.edu/~wakefield/pubs/07_Wakefield_MSThesis_Vessel.pdf","","","","","","","","","Santa Barbara, USA","University of California Santa Barbara"
"inproceedings","wakefield2006third","","Third-Order Ambisonic Extensions for Max/MSP with Musical Applications","[object Object]","[object Object],[object Object]","2006","Proceedings of the International Computer Music Conference","ICMA","This paper describes a package of extensions (externals) for Cycling `74's Max/MSP software to facilitate the exploration of Ambisonic techniques of up to third order. Areas of exploration well suited to the Max/MSP environment and techniques for composition within the Ambisonic domain using the presented externals are described.","","Graham Wakefield","Georg Essl, Ichiro Fujinaga","11","","","November","123-126","","http://quod.lib.umich.edu/i/icmc/bbp2372.2006.027/-third-order-ambisonic-extensions-for-maxmsp-with-musical?view=image","New Orleans, USA","","","","","0-9713192-4-3","","","",""