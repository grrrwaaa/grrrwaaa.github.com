%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Graham Wakefield at 2015-11-09 16:42:54 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@article{ji2016endogenous,
	Abstract = {We document techniques and insights gained through the creation of a series of ``artificial natures''--interactive visualizations of biologically-inspired complex systems that can evoke nature-like aesthetic experiences within mixed-reality art installations--since 2007. A common theme binding the various principles that emerge is the importance of endogenous accounts: that all perceivable forms have dynamic ontological roles within the world; that visitors become part of the ecosystem, both through immersive display and through interactions that induce presence; that the simulated world is able to autonomously originate; and that as a result interaction can lead to exploratory discovery. Details of how each of these principles have been applied in the visualization, sonification, and interaction design are given with specific examples of exhibited installations.},
	Annote = {In press for Jan/Feb 2016},
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Journal = {Computer Graphics and Applications},
	Month = {January},
	Publisher = {IEEE Computer Society},
	Title = {Endogenous Biologically-Inspired Art of Complex Systems},
	Year = {2016}}



@incollection{wakefield2016open,
	Commentary = {A peer-reviewed collection connecting theory and practice (techn√©) with the ontologies of interactive worlds, catalyzed by a panel discussion at the Inter-Society of Electronic Arts (ISEA) conference 2011. My chapter analyzes the challenge of creating systems that continually recreate themselves in an open-ended manner; a core problem for generative art, artificial life, and responsive environments. My contribution leverages the oft-misunderstood creative philosophy of Henri Bergson, reconciling it with computation through interactive, self-modifying and rewriting systems.},
	Abstract = {These are exciting times for world-makers. Widely-available virtual worlds, whether fully immersive virtual realities, or mixed realities that blend with or augment the real, at last appear to be imminent. This path of worldmaking is suddenly widely-backed, affordable, and accessible, with eager anticipation far beyond the catalytic space of videogames including art, design, film, architecture, information visualization, and more. It bears all the hallmarks of the birth of a new medium. The conventions have yet to be frozen, the genres crystallized, the messages of the medium deciphered. And inevitably it is being understood through a McLuhanian rear-view mirror: projecting old game tropes awkwardly into new spaces, and struggling with the loss of the frame, the cut, and the directed view of cinema. Rather than extrapolating forward from the familiar in this way, as world-makers we would rather find a path to a reach speculative goal: a creative ontology that opens upon the vast creative poiesis that the generative grains of computation make possible, making worlds that approach the open-endedness of the natural reality we inhabit, including its endless capacity to change and reveal surprisingly new and fascinating phenomena. To this end we revive the nature-inspired creative philosophy of Henri Bergson, and address the challenges and potentials of re-projecting it into interactive computational media, to illuminate a way forward.},
	Annote = {In press for 2016},
	Author = {Wakefield, Graham},
	Booktitle = {Worldmaking as Techn\'{e}: Exploring Worlds of Participatory Art, Architecture, and Music},
	Editor = {de Campo, Alberto and Hosale, Mark-David and Murrani, Sana},
	Publisher = {Riverside Architectural Press},
	Title = {Open Worlds of Self-Differentiation: Bergson And Computational Ontology},
	Year = {2016}}

@incollection{roberts2016web,
	Annote = {In press for July 2016},
	Author = {Roberts, Charles and Wakefield, Graham and Wright, Matthew},
	Booktitle = {The NIME Reader},
	Publisher = {Springer Verlag},
	Title = {Reflections on Synthesis and Instrument Design for the Browser \& The Web Browser As Synthesizer And Interface},
	Year = {2016}}

@incollection{roberts2016tensions,
	Abstract = {A review of live coding techniques building upon algorithmic descriptions of musical pattern and sound synthesis, to explore how algorithms are made and improvised with, with focus on the temporal relationship between performer, their algorithm and their performance.},
	Annote = {In press for 2016},
	Author = {Roberts, Charles and Wakefield, Graham},
	Booktitle = {The Oxford Handbook of Algorithmic Music},
	Editor = {Roger Dean and Alex McLean},
	Publisher = {Oxford University Press},
	Title = {Tensions \& Techniques in Live Coding Performance},
	Year = {2016}}

@article{wakefield2013spatial,
	Abstract = {The AlloSphere provides multiuser spatial interaction through a curved surround screen and surround sound. Two projects illustrate how researchers employed the AlloSphere to investigate the combined use of personal-device displays and the shared display. Another two projects combined multiuser interaction with multiagent systems. These projects point to directions for future ensemble-style collaborative interaction.},
	Author = {Wakefield, Graham and H\"{o}llerer, Tobias and Kuchera-Morin, JoAnn and Roberts, Charles and Wright, Matthew},
	Journal = {Computer Graphics and Applications},
	Month = {November},
	Number = {6},
	Pages = {14--20},
	Publisher = {IEEE Computer Society},
	Title = {Spatial Interaction in a Multiuser Immersive Instrument},
	Url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6682950},
	Volume = {33},
	Year = {2013},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6682950}}

@article{kuchera2014immersive,
	Abstract = {This paper describes our research in full-surround, multimodal, multi-user, immersive instrument design in a large VR instrument. The three-story instrument, designed for large-scale, multimodal representation of complex and potentially high-dimensional information, specifically focuses on multi-user participation by facilitating interdisciplinary teams of co-located researchers in exploring complex information through interactive visual and aural displays in a full-surround, immersive environment. We recently achieved several milestones in the instrument's design that improves multi-user participation when exploring complex data representations and scientific simulations. These milestones include affordances for ``ensemble-style'' interaction allowing groups of participants to see, hear, and explore data as a team using our multi-user tracking and interaction systems; separate visual display modes for rectangular legacy content and for seamless surround-view stereoscopic projection using 4 high-resolution, high-lumen projectors with hardware warping and blending integrated with 22 small-footprint projectors placed above and below the instrument's walkway; and a 3D spatial audio system enabling a variety of sound spatialization techniques. These facilities can be accessed and controlled by a multimodal framework for authoring applications integrating visual, audio, and interactive elements. We report on the achieved instrument design.},
	Author = {Kuchera-Morin, JoAnn and Wright, Matthew and Wakefield, Graham and Roberts, Charles and Adderton, Dennis and Sajadi, Behzad and H\"{o}llerer, Tobias and Majumder, Aditi},
	Doi = {10.1016/j.cag.2013.12.004},
	Journal = {Computers \& Graphics},
	Month = {May},
	Pages = {10--21},
	Publisher = {Elsevier},
	Title = {Immersive full-surround multi-user system design},
	Url = {http://www.sciencedirect.com/science/article/pii/S0097849314000090},
	Volume = {40},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0097849314000090},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.cag.2013.12.004}}

@article{zwick2008instructional,
	Author = {Zwick, Rebecca and Sklar, Jeffrey C and Wakefield, Graham and Hamilton, Cris and Norman, Alex and Folsom, Douglas},
	Journal = {Educational Measurement: Issues and Practice},
	Number = {2},
	Pages = {14--27},
	Publisher = {Wiley Online Library},
	Title = {Instructional Tools in Educational Measurement and Statistics (ITEMS) for School Personnel: Evaluation of Three Web-Based Training Modules},
	Volume = {27},
	Year = {2008}}

@article{thompson2009allobrain,
	Abstract = {This paper describes the creation of the Allobrain project, an interactive, stereoscopic, 3D audio, immersive virtual world constructed from fMRI brain data and installed in the Allosphere, one of the largest virtual reality spaces in existence. This paper portrays the role the Allobrain project played as an artwork driving the technological infrastructure of the Allosphere. The construction of the Cosm toolkit software for prototyping the Allobrain and other interactive, stereographic, 3D audio, immersive virtual worlds in the Allosphere is described in detail. Aesthetic considerations of the Allobrain project are discussed in relation to world-making as a means to understand and explore large data sets.},
	Author = {Thompson, John and Kuchera-Morin, JoAnn and Novak, Marcos and Overholt, Dan and Putnam, Lance and Wakefield, Graham and Smith, Wesley},
	Doi = {10.1016/j.ijhcs.2009.05.005},
	Journal = {International Journal of Human-Computer Studies},
	Number = {11},
	Pages = {934--946},
	Publisher = {Elsevier},
	Title = {The Allobrain: An Interactive, Stereoscopic, 3D Audio, Immersive Virtual World},
	Volume = {67},
	Year = {2009},
	Url = {http://www.sciencedirect.com/science/article/pii/S1071581909000688},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ijhcs.2009.05.005}}

@article{roberts2015designing,
	Abstract = {Native Web technologies provide great potential for musical expression. We introduce two JavaScript libraries towards this end: Gibberish.js, providing heavily optimized audio DSP, and Interface.js, a GUI toolkit that works with mouse, touch, and motion events. Together they provide a complete system for defining musical instruments that can be used in both desktop and mobile Web browsers. Interface.js also enables control of remote synthesis applications via a server application that translates the socket protocol used by Web interfaces into both MIDI and OSC messages. We have incorporated these libraries into the creative coding environment Gibber, where we provide mapping abstractions that enable users to create digital musical instruments in as little as a single line of code. They can then be published to a central database, enabling new instruments to be created, distributed, and run entirely in the browser.},
	Author = {Roberts, Charles and Wakefield, Graham and Wright, Matthew and Kuchera-Morin, JoAnn},
	Doi = {10.1162/COMJ_a_00283},
	Journal = {Computer Music Journal},
	Month = {March},
	Number = {1},
	Pages = {27--40},
	Publisher = {MIT Press},
	Title = {Designing Musical Instruments for the Browser},
	Volume = {39},
	Year = {2015},
	Url = {http://www.mitpressjournals.org/doi/abs/10.1162/COMJ_a_00283#.VkL35tBkflc},
	Bdsk-Url-1 = {http://dx.doi.org/10.1162/COMJ_a_00283}}

@incollection{smith2008computational,
	Abstract = {We describe extensions to the Lua programming language constituting a novel platform to support practice and investigation in computational audiovisual composition. Significantly, these extensions enable the tight real-time integration of computation, time, sound and space, and follow a modus operandi of development going back to immanent properties of the domain.},
	Author = {Smith, Wesley and Wakefield, Graham},
	Booktitle = {Transdisciplinary Digital Art. Sound, Vision and the New Screen},
	Doi = {10.1007/978-3-540-79486-8},
	Editor = {Adams, Randy and Gibson, Steve and M\"{u}ller Arisona, Stefan},
	Isbn = {978-3-540-79486-8},
	Journal = {Communications in Computer and Information Science},
	Pages = {213--228},
	Publisher = {Springer-Verlag Berlin Heidelberg},
	Title = {Computational Audiovisual Composition using Lua},
	Volume = {7},
	Year = {2008},
	Url = {http://link.springer.com/chapter/10.1007/978-3-540-79486-8_19},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-79486-8}}
	
@incollection{bahng2014poetry,
	Abstract = {`Poetry of Separation' is a media artwork that utilizes an algorithmic generative editing system, selecting shots in real-time to be rendered over four screens arranged in layers. Editing in cinema reconstructs images by montage, deriving meaning from the juxtaposition of multiple shots. Although multi-screen projections have been used to present sectional montages that stress the simultaneity of events, spatially separated screens can disrupt attentiveness and affective involvement; the layered architecture avoids disruptive fragmentation. The generative editing system selects shots for the layered screens stochastically, with authorial constraints and probabilities using pre-determined shot criteria. Narrative flow and authorial intents are not damaged due to these criteria, but nevertheless unexpected effects arose from the stochastic system. The authorial intentions of improvisation and separation in the film content of `Poetry of Separations' find resonance with the automatism of the generative editing system and multi-dimensionality of the screens.},
	Author = {Bahng, So Jung and Yoo, Doo Won and Hutchings, Patrick and Shi, Chung Kon and Wakefield, Graham},
	Booktitle = {Arts and Technology},
	Doi = {10.1007/978-3-319-18836-2_8},
	Isbn = {978-3-319-18835-5},
	Journal = {Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	Month = {May},
	Pages = {61--68},
	Publisher = {Springer International Publishing},
	Title = {Poetry of Separation: The Aesthetics of Spatial Montage and Generative Editing for Multi-layered Screens},
	Url = {http://link.springer.com/chapter/10.1007/978-3-319-18836-2_8},
	Venue = {Fourth International Conference, ArtsIT, Istanbul, Turkey},
	Volume = {145},
	Year = {2014},
	Bdsk-Url-1 = {http://link.springer.com/chapter/10.1007/978-3-319-18836-2_8},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/978-3-319-18836-2_8},
	Trainee = {Bahng, So Jung and Hutchings, Patrick}}

@incollection{wakefield2009artificial,
	Abstract = {Artificial Nature is a trans-disciplinary research project drawing upon bio-inspired system theories in the production of engaging immersive worlds as art installations. Embodied world making and immersion are identified as key components in an exploration of creative ecosystems toward art-as-it-could-be. A detailed account of the design of a successfully exhibited creative ecosystem is given in these terms, and open questions are outlined.},
	Commentary = {EvoMusArt forms part of the EvoSTAR European Workshops on Applications of Evolutionary Computation. Our paper describes an ongoing research project drawing upon bio-inspired system theories in the production of engaging immersive worlds as art installations. Embodied world making and immersion are identified as key components in an exploration of creative ecosystems toward art-as-it-could-be, and a detailed account of the design of a successfully exhibited creative ecosystem is given in these terms.},
	Author = {Wakefield, Graham and Ji, Haru (Hyunkyung)},
	Booktitle = {Applications of Evolutionary Computing},
	Doi = {10.1007/978-3-642-01129-0},
	Editor = {Mario Giacobini and Anthony Brabazon and Stefano Cagnoni and Aniko Ekart and Anna I. Esparcia-Alc{\'a}zar and Muddassar Farooq and Andreas Fink and Penousal Machado and Jon McCormack and Michael O'Neill and Ferrante Neri and Mike Preuss and Franz Rothlauf and Ernesto Tarantino and Shengxiang Yang},
	Isbn = {978-3-642-01128-3},
	Journal = {Theoretical Computer Science and General Issues},
	Pages = {597--602},
	Publisher = {Springer-Verlag Berlin Heidelberg},
	Title = {Artificial nature: Immersive world making},
	Venue = {The Evolutionary Music and Art Workshop, T\"{u}bingen},
	Volume = {5484},
	Year = {2009},
	Url = {http://link.springer.com/chapter/10.1007%2F978-3-642-01129-0_68},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-642-01129-0}}

@incollection{putnam2010immersed,
	Commentary = {A chapter for a popular book series focusing on visualization, describing work by the AlloSphere Research Group at the California NanoSystems Institute, UC Santa Barbara. My contributions included the opening sections of strategy and philosophy, as well as content and software design, followed by two sections describing specific application implementations. O‚ÄôReilly Media‚Äôs ‚ÄúBeautiful...‚Äù book series has been very successful and widely acclaimed.},
	Author = {Putnam, Lance and Wakefield, Graham and Ji, Haru (Hyunkyung) and Alper, Basak and Adderton, Dennis and Kuchera-Morin, JoAnn},
	Booktitle = {Beautiful Visualization: Looking at Data through the Eyes of Experts},
	Editor = {Steele, Julie and Iliinsky, Noah},
	Pages = {291-310},
	Publisher = {O'Reilly Media, Inc.},
	Title = {Immersed in Unfolding Complex Systems},
	Url = {http://shop.oreilly.com/product/0636920000617.do},
	Year = {2010}}

@incollection{bahng2014digital,
	Abstract = {The instant messenger has developed as an important communication media platform. However, because of the nature of instant communication, instant messenger services place many limitations on communicating with nuance. We believe that the easy nature of digital communications tends to weaken serious aspects of personal communication such as patience and commitment. On the basis of critical perspectives, we designed the digital messenger `Digital Love Letter' (DLL)': a mobile messenger in which the expressive process of interaction is more important than the final output. The main concept of DLL is to share the process of communication using a non-instantaneous and non-multitasking interface, so that users can share their time with some similar nuances to face-to-face communication. Both writing and reading messages require concentrated attention. Thus, this paper suggests a new system of digital messenger, that is also a new method of computer-mediated communication (CMC).},
	Author = {Bahng, So Jung and Song, Yoonji and Kim, Jae Dong and Suh, Kiseul and Shi, Chung-Kon and Wakefield, Graham and Woo, Sungju},
	Booktitle = {Human-Computer Interaction. Applications and Services},
	Doi = {10.1007/978-3-319-07227-2_11},
	Isbn = {978-3-319-07226-5},
	Journal = {Lecture Notes in Computer Science},
	Month = {June},
	Pages = {103--113},
	Publisher = {Springer International Publishing},
	Title = {Digital Love Letter: A Handwriting Based Interface for Non-instant Digital Messenger},
	Venue = {HCI International, Heraklion, Crete, Greece},
	Volume = {8512},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-319-07227-2_11},
	Trainee = {Bahng, So Jung and Hutchings, Patrick}}

@incollection{jang2014airsculpt,
	Abstract = {In this paper, we present a new kind of wearable augmented reality (AR) 3D sculpting system called AiRSculpt in which users could directly translate their fluid finger movements in air into expressive sculptural forms and use hand gestures to navigate the interface. In AiRSculpt, as opposed to VR-based systems, users could quickly create and manipulate 3D virtual content directly with their bare hands in a real-world setting, and use both hands simultaneously in tandem or as separate tools to sculpt and manipulate their virtual creations. Our system uses a head-mounted display and a RGB-D head-mounted camera to detect the 3D location of hands and fingertips then render virtual content in calibration with real-world coordinates.},
	Author = {Jang, Sung-A and Kim, Hyung-il and Woo, Woontack and Wakefield, Graham},
	Booktitle = {Distributed, Ambient, and Pervasive Interactions},
	Doi = {10.1007/978-3-319-07788-8_13},
	Isbn = {978-3-319-07787-1},
	Journal = {Lecture Notes in Computer Science},
	Month = {June},
	Pages = {130--141},
	Publisher = {Springer International Publishing},
	Title = {AiRSculpt: A Wearable Augmented Reality 3D Sculpting System},
	Venue = {HCI Interational, Heraklion, Crete, Greece},
	Volume = {8530},
	Year = {2014},
	Url = {http://link.springer.com/chapter/10.1007%2F978-3-319-07788-8_13#page-1},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-319-07788-8_13},
	Trainee = {Jang, Sung-A}}
	
@incollection{amatriain2008experiencing,
	Abstract = {The UCSB Allosphere is a 3-story-high spherical instrument in which virtual environments and performances can be experienced in full immersion. The space is now being equipped with high-resolution active stereo projectors, a 3D sound system with several hundred speakers, and with tracking and interaction mechanisms. The Allosphere is at the same time multimodal, multimedia, multi-user, immersive, and interactive. This novel and unique instrument will be used for research into scientific visualization/auralization and data exploration, and as a research environment for behavioral and cognitive scientists. It will also serve as a research and performance space for artists exploring new forms of art. In particular, the Allosphere has been carefully designed to allow for immersive music and aural applications. In this paper, we give an overview of the instrument, focusing on the audio subsystem. We give the rationale behind some of the design decisions and explain the different techniques employed in making the Allosphere a truly general-purpose immersive audiovisual lab and stage. Finally, we present first results and our experiences in developing and using the Allosphere in several prototype projects.},
	Author = {Amatriain, Xavier and Castellanos, Jorge and H\"{o}llerer, Tobias and Kuchera-Morin, JoAnn and Pope, Stephen T and Wakefield, Graham and Wolcott, Will},
	Booktitle = {Computer Music Modeling and Retrieval. Sense of Sounds},
	Doi = {10.1007/978-3-540-85035-9},
	Editor = {Richard Kronland-Martinet and S{\o}lvi Ystad and Kristoffer Jensen},
	Isbn = {978-3-540-85034-2},
	Journal = {Information Systems and Applications},
	Pages = {380--400},
	Publisher = {Springer},
	Title = {Experiencing Audio and Music in a Fully Immersive Environment},
	Volume = {4969},
	Year = {2008},
	Url={http://link.springer.com/chapter/10.1007%2F978-3-540-85035-9_27},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-85035-9}}
	
	@incollection{wakefield2012virtual,
	Abstract = {Time of Doubles is an immersive, interactive art installation, and an instantiation of contemporary art research on the creation of possible worlds. It invites visitors to experience mirror existences of themselves taking upon new roles as sources of energy and kinetic disturbance within a perpetually changing virtual ecosystem. This world displays some characteristics familiar from our own, but is populated by unfamiliar life forms singing, swimming, and breeding through sensitive motions of dark fluids. The visitors' doubles are energy fields, which emanate myriad bright fluid particles, food sources to be eaten by the virtual organisms. Visitors see, hear, and feel how they are fed to unknown species in this virtual ecosystem. The immersive multimodal environment and volumetric sensors take the visitors beyond avatar-based interaction to become embodied within a world of physical and biological activity. The installation has been presented in gallery settings and CAVE-like environments utilizing 3D depth cameras, stereographic display and surround audio. As an immersive audio-visual installation, it brings forth a world of aesthetic play through the embodiment of complex multi-layered and inter-modulating systems. In this paper, the artists describe Time of Doubles from its conceptual foundations, developmental process and installation construction.},
	Annote = {Representative chapter.},
	Author = {Wakefield, Graham and Ji, Haru (Hyunkyung)},
	Booktitle = {Virtual Worlds},
	Editor = {Stephan Bornhofen and Jean-Claude Heudin and Alain Lioret and Jean-Claude Torrel},
	Isbn = {979-10-91245-06-7},
	Month = {November},
	Publisher = {Science eBook, Paris},
	Title = {Virtual World-Making in an Interactive Art Installation: Time of Doubles},
	Url = {http://www.science-ebook.fr/bonus/virtual_worlds_extrait.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://www.science-ebook.fr/bonus/virtual_worlds_extrait.pdf}}

@incollection{kim2015toward,
	Abstract = {Aiming for high-level intentional control of audio feedback, though microphones, loudspeakers and digital signal processing, we present a system adapting toward chosen sonic features. Users control the system by selecting and changing feature objectives in real-time. The system has a second-order structure in which the internal signal processing algorithms are developed according to an evolutionary process. Genotypes develop into signal-processing algorithms, and fitness is measured by analysis of the incoming audio feedback. A prototype is evaluated experimentally to measure changes of audio feedback depending on the chosen target conditions. By enhancing interactivity of an audio feedback through the intentional control, we expect that feedback systems could be utilized more effectively in the fields of musical interaction, finding balance between nonlinearity and interactivity.},
	Author = {Kim, Seunghun and Nam, Juhan and Wakefield, Graham},
	Booktitle = {Evolutionary and Biologically Inspired Music, Sound, Art and Design},
	Doi = {10.1007/978-3-319-16498-4_11},
	Isbn = {978-3-319-16497-7},
	Journal = {Lecture Notes in Computer Science},
	Month = {April},
	Pages = {113--124},
	Publisher = {Springer International Publishing},
	Title = {Toward Certain Sonic Properties of an Audio Feedback System by Evolutionary Control of Second-Order Structures},
	Venue = {The 4th International Conference EvoMUSART, Copenhagen},
	Volume = {9027},
	Year = {2015},
	Url={http://link.springer.com/chapter/10.1007%2F978-3-319-16498-4_11},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-319-16498-4_11},
	Trainee = {Kim, Seunghun}}

@incollection{wakefield2009machinic,
	Author = {Wakefield, Graham},
	Booktitle = {Machine Dreams},
	Editor = {Jeon, Byeong Sam and Ji, Haru (Hyunkyung)},
	Isbn = {978-89-963788-0-8},
	Pages = {120--123},
	Publisher = {KoIAN},
	Title = {Makeshift, Machinic / Open},
	Venue = {Seoul, Republic of Korea},
	Year = {2009}}

@inproceedings{wakefield2006third,
	Abstract = {This paper describes a package of extensions (externals) for Cycling `74's Max/MSP software to facilitate the exploration of Ambisonic techniques of up to third order. Areas of exploration well suited to the Max/MSP environment and techniques for composition within the Ambisonic domain using the presented externals are described.},
	Author = {Wakefield, Graham},
	Booktitle = {Proceedings of the International Computer Music Conference},
	Editor = {Georg Essl and Ichiro Fujinaga},
	Isbn = {0-9713192-4-3},
	Month = {November},
	Pages = {123--126},
	Publisher = {ICMA},
	Title = {Third-Order Ambisonic Extensions for Max/MSP with Musical Applications},
	Venue = {New Orleans, USA},
	Url = {http://quod.lib.umich.edu/i/icmc/bbp2372.2006.027/--third-order-ambisonic-extensions-for-maxmsp-with-musical?view=image},
	Year = {2006}}

@inproceedings{smith2007real,
	Abstract = {In this paper, we present a new interface for programming multimedia compositions in Max/ MSP/Jitter using the Lua scripting language. Lua is extensible and efficient making it an ideal 
choice for designing a programmatic interface for multimedia compositions. First, we discuss the distinctions of graphical and textual interfaces for composition and the requirements for a productive compositional workflow, and then we describe domain specific implementations of Lua bindings as Max externals for graphics and audio in that order.},
	Author = {Wakefield, Graham and Smith, Wesley},
	Booktitle = {Proceedings of the Digital Art Weeks},
	Editor = {Stefan M\"{u}ller Arisona},
	Month = {July},
	Publisher = {Digital Art Weeks International},
	Title = {Using Lua for Multimedia Composition},
	Venue = {Zurich, Switzerland},
	Year = {2007}}

@inproceedings{wakefield2007real,
	Abstract = {In this paper, we present new opportunities to overcome some of the inherent limitations of a visual data-flow environment such as Max/MSP/Jitter, by using domain specific (audio and graphical) extensions of the Lua programming language as libraries (externals). Lua is flexible, extensible and efficient, making it an ideal choice for designing a programmatic interface for multimedia composition.},
	Author = {Smith, Wesley and Wakefield, Graham},
	Booktitle = {Proceedings of the International Computer Music Conference},
	Month = {August},
	Pages = {341--344},
	Publisher = {ICMA},
	Title = {Real-time Multimedia Composition using Lua},
	Venue = {Copenhagen, Denmark},
	Year = {2007}}

@inproceedings{ji2008artificialasia,
	Abstract = {A virtual embodiment of an auto-creative world: generative, interactive transmodal media art installation bringing forth an ecosystem of creativity through a meshwork of strata (geo-, chemo-, bio-, sono-), re-questioning the meanings and relationships of nature, culture, life and beauty.},
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Booktitle = {Proceedings of ASIAGRAPH},
	Date-Modified = {2015-11-09 21:42:51 +0000},
	Month = {July},
	Publisher = {ASIAGRAPH},
	Title = {Artificial Nature as an Infinite Game},
	Venue = {Shanghai, China},
	Year = {2008}}

@inproceedings{ji2008artificial,
	Abstract = {``Artificial Nature as an Infinite Game'' is a trans-modal media art installation consisting of an evolutionary virtual world with a physical user interface. This virtual world is a complex, open, dynamical and dissipative system, interweaving physico-chemical, biological and symbolic strata. In actual space, spectators can witness, control and discover beautiful, generative and abstract spatio-temporal patterns evolving from the behaviors of A-life agencies in the virtual space, while the art work itself is questioning of a new understanding the concept of beauty and creativity in nature, culture and actual, virtual world.},
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Booktitle = {Proceedings of the International Symposium of Electronic Arts},
	Editor = {Ingrid Maria Hoofd, Margaret Tan, Katharine Ho Kit Ying},
	Isbn = {978-981-08-0768-9},
	Month = {August},
	Pages = {256--258},
	Publisher = {The Inter-Society for the Electronic Arts},
	Title = {Artificial Nature as an Infinite Game},
	Venue = {Singapore},
	Year = {2008}}

@inproceedings{wakefield2008allobrain,
	Abstract = {This document describes the AlloBrain, the debut content created for presentation in the AlloSphere at the University of California, Santa Barbara, and the Cosm toolkit for the prototyping of interactive immersive environments using higher-order Ambisonics and stereoscopic projections. The Cosm toolkit was developed in order to support the prototyping of immersive applications that involve both visual and sonic interaction design. Design considerations and implementation details of both the Cosm toolkit and the AlloBrain are described in detail, as well as the development of custom human-computer interfaces and new audiovisual interaction methodologies within a virtual environment.},
	Commentary = {The article introduces the first project created for the CNSI AlloSphere at UC Santa Barbara (a 3-storey spherical CAVE-like environment), which provides an interactive, navigable world visualizing and sonifying fMRI brain data, of which I was the primary implementor. The article was extended for the International Journal of Human Computer Studies.},
	Author = {Wakefield, Graham and Kuchera-Morin, JoAnn and Novak, Marcos and Overholt, Dan and Putnam, Lance and Thompson, John and Smith, Wesley},
	Booktitle = {Proceedings of the CHI Conference Workshop on Sonic Interaction Design (SID-CHI)},
	Editor = {Davide Rocchesso and Gerhard Eckel and Stefania Serafin and Thomas Hermannand Frauke Behrendtand Sandra Pauletto and Nicola Bernardini and Patrick Susini and Roberto Bresin and Yon Visell},
	Isbn = {978-1-60558-012-8/08/04},
	Month = {April},
	Publisher = {ACM},
	Title = {The AlloBrain: an Interactive Stereoscopic, 3D Audio Immersive Environment},
	Venue = {Florenz, Italy},
	Year = {2008}}

@inproceedings{ji2009artificial,
	Abstract = {Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories in the production of engaging aesthetic immersive worlds. As a creative ecosystem, three virtual strata - inanimate, animate, and behavioral - truly captivate the viewer through multi-sensory interactions by drawing (touch), singing (audio), dancing (movement, visual) and navigating (movement, touch).},
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Booktitle = {Proceedings of the NSF Media Arts, Science and Technology Conference},
	Publisher = {National Science Foundation},
	Title = {Artificial Nature},
	Venue = {Santa Barbara, USA},
	Year = {2009}}

@inproceedings{smith2009computational,
	Abstract = {In this paper we put forward a notion of computational composition: an exploratory approach to creativity uniquely available by means of computation. The implications for an expanded overlap of the intellectual and computational are discussed and developed into a design strategy. Finally we describe progress on our implementation.},
	Author = {Smith, Wesley and Wakefield, Graham},
	Booktitle = {Proceedings of the NSF Media Arts, Science and Technology Conference},
	Publisher = {National Science Foundation},
	Title = {Computational Composition and Creativity},
	Venue = {Santa Barbara, USA},
	Year = {2009}}

@inproceedings{ji2009artificialrandd,
	Abstract = {Artificial Nature is a trans-disciplinary multimodal interactive art installation and a research subject investigating the application of bio-inspired system theories towards engaging aesthetic world-making. Our motivation is to develop a deeper understanding of emergence and creativity as a form of art, study and play, by taking inspiration from nature's creativity while recognizing the potential of natural creation beyond the known and the physical. In this paper we trace the progression of Artificial Nature from original inspirations through diverse prototypes to elaborate immersive installations.},
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Booktitle = {The 2nd International Conference on Media Art and Information Aesthetics},
	Month = {July},
	Publisher = {CAFA Art Museum},
	Title = {Artificial Nature: Research and Development},
	Venue = {Beijing, China},
	Year = {2009}}

@inproceedings{roberts2010dynamic,
	Abstract = {We present the Device Server, a framework and application driving interaction in the AlloSphere virtual reality environment. The motivation and development of the Device Server stems from the practical concerns of managing multi-user interactivity with a variety of physical devices for disparate performance and virtual reality environments housed in the same physical location. The interface of the Device Server allows users to see how devices are assigned to application functionalities, alter these assignments and save them into configuration files for later use. Configurations defining how applications use devices can be changed on the fly without recompiling or relaunching applications. Multiple applications can be connected to the Device Server concurrently. The Device Server provides several conveniences for performance environments. It can process control data efficiently using Just-In-Time compiled Lua expressions; in doing so it frees processing cycles on audio and video rendering computers. All control signals entering the Device Server can be recorded, saved, and played back allowing performances based on control data to be recreated in their entirety. The Device Server attempts to homogenize the ap- pearance of different control signals to applications so that users can assign any interface element they choose to application functionalities and easily experiment with different control configurations.},
	Author = {Roberts, Charles and Wright, Matthew and Kuchera-Morin, JoAnn and Putnam, Lance and Wakefield, Graham},
	Booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression (NIME)},
	Month = {June},
	Pages = {57--62},
	Title = {Dynamic Interactivity inside the AlloSphere},
	Url = {http://www.nime.org/proceedings/2010/nime2010_057.pdf},
	Venue = {Sydney, Australia},
	Year = {2010},
	Url = {http://www.nime.org/wp-publications/roberts2010/},
	Bdsk-Url-1 = {http://www.nime.org/proceedings/2010/nime2010_057.pdf}}

@inproceedings{smith2009augmenting,
	Abstract = {We discuss the potential of just-in-time compilation for computer music software to evade compromises of flexibility and efficiency due to the discrepencies between the respective natures of composition and computation and also to augment exploratory and generative capacity. We present a range of examples and approaches using LLVM compiler infrastructure within the LuaAV composition environment and measure its performance against static compilation.},
	Author = {Smith, Wesley and Wakefield, Graham},
	Booktitle = {Proceedings of the International Computer Music Conference},
	Month = {August},
	Pages = {439--442},
	Publisher = {ICMA},
	Title = {Augmenting Computer Music with Just-In-Time Compilation},
	Venue = {Montreal, Canada},
	Url = {http://quod.lib.umich.edu/i/icmc/bbp2372.2009.100/--augmenting-computer-music-with-just-in-time-compilation?view=image&seq=1&size=100},
	Year = {2009}}

@inproceedings{ji2009fluid,
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Booktitle = {Proceedings of SIGGRAPH ASIA Art Gallery & Emerging Technologies: Adaptation},
	Doi = {10.1145/1665137.1665153},
	Editor = {Tomoe Moriyama and Stephanie Choo},
	Isbn = {978-1-60558-878-0},
	Month = {December},
	Pages = {26--26},
	Publisher = {ACM},
	Title = {Artificial Nature: Fluid Space},
	Venue = {Yokohama, Japan},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1665137.1665153}}

@inproceedings{ji2011time,
	Abstract = {"Time of Doubles" is an immersive interactive art installation. It invites visitors to experience mirror existences of themselves taking upon new roles as sources of energy and kinetic disturbance within a virtual ecosystem, a uniquely created computational world. Visitors encounter their doubles in a deep hyper space with 3D stereoscopic projection and 3D depth cameras. The immersive projection dissolves the illusion of a window to form an entryway into a shared, co-present world, and the volumetric sensors take the visitors beyond avatar-based representation to become embodied within a world of physical simulation. This world displays some familiar characteristics as our own, but is populated by unfamiliar life-forms swimming through the sensitive motions of dark fluids and singing continuously. The visitor doubles are energy fields which emanate myriad bright fluid particles, food sources which are eaten by the virtual organisms. Visitors hear, see and feel how they are fed to unknown species in the virtual ecosystem aesthetically. Without visitors, the world-fluid is filled with life seeds that cannot grow, but with a human presence the populations explode into alien orchestras. Larger organisms leave physical residues and films behind as they pass, which constrain the fluid flows and which can be sculpted by visitor doubles.},
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Booktitle = {Proceedings of SIGGRAPH ASIA Art Gallery},
	Doi = {10.1145/2077355.2425799},
	Editor = {Rochelle Yang},
	Isbn = {978-1-4503-1133-5},
	Month = {December},
	Pages = {26--26},
	Publisher = {ACM},
	Title = {Time of Doubles},
	Venue = {Hong Kong},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2077355.2425799}}

@inproceedings{wakefield2010luaav,
	Abstract = {We describe LuaAV, a runtime library and applica- tion which extends the Lua programming language to support computational composition of temporal, sound, visual, spatial and other elements. In this paper we document how we have attempted to maintain several core principles of Lua itself - extensibility, meta-mechanisms, efficiency, portabil- ity - while providing the flexibility and temporal accuracy demanded by interactive audio-visual media. Code generation is noted as a recurrent strategy for increasingly dynamic and extensible environments.},
	Author = {Wakefield, Graham and Smith, Wesley and Roberts, Charles},
	Booktitle = {Proceedings of the Linux Audio Conference},
	Editor = {Maurits Lamers},
	Month = {May},
	Pages = {31--38},
	Publisher = {Hogeschool voor de Kunsten},
	Title = {LuaAV: Extensibility and heterogeneity for audiovisual computing},
	Venue = {Utrecht, the Netherlands},
	Year = {2010}}

@inproceedings{wakefield2014collaborative,
	Abstract = {We discuss live coding audio-visual worlds for large-scale virtual reality environments. We describe Alive, an instrument allowing multiple users to develop sonic and visual behaviors of agents in a virtual world, through a browser based collaborative code interface, accessible while being immersed through spatialized audio and stereoscopic display. The interface adds terse syntax for query-based precise or stochastic selections and declarative agent manipulations, lazily-evaluated expressions for synthesis and behavior, event handling, and flexible scheduling.},
	Author = {Graham Wakefield and Charlie Roberts and Matthew Wright and Timothy Wood and Karl Yerkes},
	Booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
	Month = {June},
	Pages = {505--508},
	Publisher = {Goldsmiths, University of London},
	Title = {Collaborative Live-Coding with an Immersive Instrument},
	Url = {http://www.nime.org/proceedings/2014/nime2014_328.pdf},
	Venue = {London, United Kingdom},
	Year = {2014},
	Url = {http://nime2014.org/proceedings/papers/328_paper.pdf},
	Bdsk-Url-1 = {http://www.nime.org/proceedings/2014/nime2014_328.pdf}}

@inproceedings{roberts2012mobile,
	Abstract = {Designing mobile interfaces for computer-based musical performance is generally a time-consuming task that can be exasperating for performers. Instead of being able to experiment freely with physical interfaces' affordances, performers must spend time and attention on non-musical tasks including network configuration, development environments for the mobile devices, defining OSC address spaces, and handling the receipt of OSC in the environment that will control and produce sound. Our research seeks to overcome such obstacles by minimizing the code needed to both generate and read the output of interfaces on mobile devices. For iOS and Android devices, our implementation extends the application Control to use a simple set of OSC messages to define interfaces and automatically route output. On the desktop, our implementations in Max/MSP/Jitter, LuaAV, and Su-perCollider allow users to create mobile widgets mapped to sonic parameters with a single line of code. We believe the fluidity of our approach will encourage users to incorporate mobile devices into their everyday performance practice.},
	Author = {Charles Roberts and Graham Wakefield and Matt Wright},
	Booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
	Publisher = {University of Michigan},
	Title = {Mobile Controls On-The-Fly: An Abstraction for Distributed NIMEs},
	Url = {http://www.nime.org/proceedings/2012/nime2012_303.pdf},
	Venue = {Ann Arbor, Michigan},
	Year = {2012},
	Url = {http://www.nime.org/wp-publications/roberts2012/},
	Bdsk-Url-1 = {http://www.nime.org/proceedings/2012/nime2012_303.pdf}}

@inproceedings{roberts2013web,
	Abstract = {Web technologies provide an incredible opportunity to present new musicalinterfaces to new audiences. Applications written in JavaScript and designed torun in the browser offer remarkable performance, mobile/desktop portability andlongevity due to standardization. Our research examines the use and potentialof native web technologies for musical expression. We introduce two libraries towards this end: Gibberish.js, a heavily optimized audio DSP library, and Interface.js, a GUI toolkit that works with mouse, touch and motion events.Together these libraries provide a complete system for defining musicalinstruments that can be used in both desktop and mobile browsers. Interface.jsalso enables control of remote synthesis applications by including an application that translates the socket protocol used by browsers into both MIDI and OSC messages.},
	Commentary={NIME is the foremost conference for human-computer interaction in a musical context. NIME 2013 was notably marked by the increased interest and research using new web technologies for interactive audio synthesis, mobile device interaction, multi-user server apps and live-coding. Our paper presented results in all these areas through the gibberish.js and interface.js libraries, leveraging code generation to support optimized single-sample feedback, and automatic web interface generation. It was selected as best paper of the conference, was expanded in Computer Music Journal (MIT Press), and will be reprinted with additional commentary in The NIME Reader.},
	Annote = {Awarded best paper.},
	Author = {Roberts, Charles and Wakefield, Graham and Wright, Matthew},
	Booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
	Editor = {Kyogu Lee},
	Month = {May},
	Pages = {313--318},
	Publisher = {Graduate School of Culture Technology, KAIST},
	Title = {The web browser as synthesizer and interface},
	Url = {http://nime.org/proceedings/2013/nime2013_282.pdf},
	Venue = {Daejeon, Republic of Korea},
	Year = {2013},
	Bdsk-Url-1 = {http://nime.org/proceedings/2013/nime2013_282.pdf}}

@inproceedings{ji2015endogenous,
	Abstract = {We document techniques and insights gained through the creation of interactive visualizations of biologically-inspired complex systems that have been exhibited as mixed-reality art installations since 2007. A binding theme is the importance of endogenous accounts: that all perceivable forms have dynamic ontological capacities within the world; that the simulated world is able to autonomously originate; that as a result interaction can lead to exploratory discovery; and that visitors become part of the ecosystem, both through immersive display and through interactions that induce presence. Details of how each of these components have been applied in the visualization, sonification, and interaction design are given with specific examples of prototypes and exhibited installations.},
	Author = {Ji, Haru (Hyunkyung) and Wakefield, Graham},
	Booktitle = {Proceedings of the IEEE VIS Arts Program},
	Editor = {Angus Forbes and Fanny Chevalier and Daria Tsoupikova},
	Month = {October},
	Pages = {30--37},
	Publisher = {University of Illinois at Chicago},
	Title = {Endogenous Biologically-Inspired Visualization Immersed Within an Art of Complex Systems},
	Url = {http://visap.uic.edu/2015/VISAP15-Papers/visap2015_Ji_BiologicallyInspired.pdf},
	Venue = {Chicago, USA},
	Year = {2015},
	Bdsk-Url-1 = {http://visap.uic.edu/2015/VISAP15-Papers/visap2015_Ji_BiologicallyInspired.pdf}}

@inproceedings{kim2015augmenting,
	Abstract = {This paper presents the interactive enhancement of audio feedback through context-based control, leading to the generation of desired sonic behaviors by augmenting the effects of physical space in the feedback sound. Our prototype maps approximations of room reverberation to tempo-scale characteristics of the audio feedback. These characteristics are generated by a combination of adaptive amplification control and a digital variable delay line in the feedback loop. Room reverberation is inferred from the feedback sound by real-time cross-correlation of input with output signals, which is used to guide the variable delay line. This variation, coupled with an adaptive gain control, determines room-dependent tempo effects.},
	Author = {Seunghun Kim and Graham Wakefield and Juhan Nam},
	Booktitle = {Proceedings of the International Computer Music Conference},
	Month = {September},
	Publisher = {University of North Texas},
	Title = {Augmenting Room Acoustics and System Interaction for Intentional Control of Audio Feedback},
	Venue = {Denton, USA},
	Year = {2015},
	Trainee = {Kim, Seunghun}}
	
@inproceedings{kim2016sonic,
	Author = {Seunghun Kim and Changheun Oh and Graham Wakefield and Juhan Nam},
	Booktitle = {Proceedings of the International Symposium of Electronic Art},
	Annote = {Extended abstract.},
	%Month = {September},
	%Publisher = {University of North Texas},
	Title = {Sonic Participation in the Evolving Audio Feedback System},
	%Venue = {Denton, USA},
	Year = {2016},
	Trainee = {Kim, Seunghun}}

@inproceedings{wakefield2013becoming,
	Abstract = {A discussion of the theoretical perspectives on immersion, presence and agency in VR and HCI research, with a new application to large-scale interactive, generative artworks. The task-centric approach common to VR HCI research may be inappropriate to encompass the inclusivity and open-endedness of art experience; however several aspects of presence and agency (``being together'', ``being able to do'') are found to have direct relevance. A new mode of presence concerning our relationship with a simulated biological environment is proposed.},
	Annote = {Keynote paper.},
	Author = {Wakefield, Graham and Ji, Haru (Hyunkyung)},
	Booktitle = {International Symposium on Ubiquitous Virtual Reality},
	Doi = {10.1109/ISUVR.2013.14},
	Isbn = {978-0-7695-5084-8},
	Month = {July},
	Pages = {11--14},
	Publisher = {IEEE Computer Society},
	Title = {Becoming-There: Natural Presence in an Art of Artificial Ecologies},
	Url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6597723},
	Venue = {Daejeon, Republic of Korea},
	Year = {2013},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6597723},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/ISUVR.2013.14}}

@inproceedings{wakefield2011cosm,
	Abstract = {Spatial music can create immersive experiences of alter- nate realities. To what degree can this be expanded to the composition of immersive, navigable, audio-visual worlds? We present an integrated collection of exten- sions to the Max/MSP/Jitter environment to assist the tightly integrated construction of such worlds, designed for use within audio-visual virtual environments and other projects using spatial simulation. The perspective taken is that spatial composition can go beyond the specification of locations and trajectories to the composition of auton- omy, agency and interactions.},
	Author = {Wakefield, Graham and Smith, Wesley},
	Booktitle = {Proceedings of the International Computer Music Conference},
	Month = {July},
	Pages = {13--20},
	Publisher = {ICMA},
	Title = {Cosm: A toolkit for composing immersive audio-visual worlds of agency and autonomy},
	Url = {http://quod.lib.umich.edu/i/icmc/bbp2372.2011.004/--cosm-a-toolkit-for-composing-immersive-audio-visual-worlds},
	Venue = {Huddersfield, UK},
	Year = {2011},
	Bdsk-Url-1 = {http://quod.lib.umich.edu/i/icmc/bbp2372.2011.004/--cosm-a-toolkit-for-composing-immersive-audio-visual-worlds}}

@inproceedings{bang2014lost,
	Abstract = {`Lost Fragments of Night' is a poetic documentary film that utilizes an algorithmic generative editing system to preselect shots to be rendered over four screens arranged in layers. The artwork's subject is the chaotic and contradictory sensations found by night in the city of Seoul. In this work, the themes of disconnected and paradoxical images in urban public spaces resonate with the concepts of the multi-layered screens and generative editing system. The fragmented images are distributed over layers of screens to emphasize a chaotic and simultaneous sense of fragility that nevertheless together forms a whole. Designed for large-scale installation in urban public spaces, our artwork has been prototyped via a physical miniature, projecting by rear diffusion onto four layered screens constructed of grey sheer fabric. The audience can appreciate the montage from different angles and positions to produce different layering effects not possible in traditional 2D cinema. The generative editing system uses a dynamic Bayesian network constructed according to clips and timeline tagging. Audience members can actively contribute to the direction of the montage through a web interface, so the artwork creates different experiences by embracing the role of the audience in every screening.},
	Author = {Bahng, So Jung and Hutchings, Patrick and Yoo Doo Won and Wakefield, Graham},
	Booktitle = {Proceedings of the International Symposium on Electronic Arts},
	Editor = {Brad Moody and Marta Ameri and Thorsten Lomker},
	Month = {October},
	Publisher = {The Inter-Society for the Electronic Arts},
	Title = {Generative Spatial Montage with Multi-Layered Screens in \"Lost Fragments of Night\"},
	Venue = {Dubai},
	Year = {2014},
	Trainee = {Bahng, So Jung and Hutchings, Patrick}}

@phdthesis{wakefield2012phdthesis,
	Abstract = {In the interactive computer arts, any advance that significantly amplifies or extends the limits and capacities of software can enable genuinely novel aesthetic experiences. Within compute-intensive media arts, flexibility is often sacrificed for needs of efficiency, through the total separation of machine code optimization and run-time execution. Compromises based on modular run-time combinations of prior-optimized `black box' components confine results to a pre-defined palette with less computational efficiency overall: limiting the open-endedness of development environments and the generative scope of artworks. This dissertation demonstrates how the trade-off between flexibility and efficiency can be relaxed using reflective meta-programming and dynamic compilation: extending a pro- gram with new efficient routines while it runs. It promises benefits of more open- ended real-time systems, more complex algorithms, richer media, and ultimately unprecedented aesthetic experiences. The dissertation charts the significant differences that this approach implies for interactive computational arts, builds a conceptual framework of techniques and requirements to respond to its challenges, and documents supporting implementations in two specific scenarios. The first concentrates on open-ended creativity support within always-on authoring environments for studio work and live cod- ing performance, while the second concerns the open-endedness of generative art through interactive, immersive artificial-life worlds.},
	Commentary = {My doctoral research focused on run-time code generation and dynamic compilation for interactive computational arts.  Run-time code generation opens up a vast possibility space for execution flow, valuable both for creative sketching and authoring environments, as well as artificial life and other generative systems. Dynamic compilation can ensure the efficiency of generated code in real-time scenarios, however it has been hitherto only rarely utilized in computational arts. The theoretical framework presented in the first half of the dissertation is evaluated in the context of its application in authoring environments and interactive artworks. One such application is the Gen extension to Max/MSP/Jitter, which extends a well-known visual data-flow programming environment for audio to support efficient single-sample feedback, with novel capabilities for filter design, physical modeling etc. Gen was released as a commercial product in 2011 and has now tens of thousands of users, and has been the basis of several graduate-level courses (unrelated to the author). A second application integrates into the author‚Äôs ‚ÄúTime of Doubles‚Äù interactive artwork, in which populations of thousands of organisms continuously interact with users, metabolizing and reproducing on time-scales of seconds. Using code generation and dynamic compilation, each newly born organism embeds a uniquely generated, evolved piece of machine code, allowing a much greater space of behavior without compromising population size. This version of the artwork has been successfully exhibited at three international events since 2011. (Separate publications of the project contributions are in progress.)},
	Address = {Santa Barbara, USA},
	Author = {Graham Wakefield},
	Month = {September},
	School = {University of California Santa Barbara},
	Title = {Real-Time Meta-Programming for Interactive Computational Arts},
	Year = {2012}}

@mastersthesis{wakefield2007mastersthesis,
	Abstract = {The rich new terrains offered by computer music invite the exploration of new techniques to compose within them. The computational nature of the medium has suggested algorithmic approaches to composition in the form of generative musical structure at the note level and above, and audio signal processing at the level of individual samples. In the region between these levels, the domain of microsound, we may wish to investigate the musical potential of sonic particles that interrelate both signal processing and generative structure. In this thesis I present a software platform (`Vessel') for the exploration of such potential. In particular, a solution to the efficient scheduling of interleaved sound synthesis and algorithmic control with sample accuracy is expounded. The formal foundations, design and implementation are described, the project is contrasted with existing work, and avenues for musical application and future exploration are proposed.},
	Address = {Santa Barbara, USA},
	Author = {Graham Wakefield},
	Month = {June},
	School = {University of California Santa Barbara},
	Title = {Vessel: A Platform for Computer Music Composition, Interleaving Sample-Accurate Synthesis and Control},
	Url = {http://www.mat.ucsb.edu/~wakefield/pubs/07_Wakefield_MSThesis_Vessel.pdf},
	Year = {2007}}